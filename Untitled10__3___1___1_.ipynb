{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZTzBlwv2qoo",
        "outputId": "14e4bfc6-4465-4dc7-bc5b-9561b5d49476"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate==0.21.0\n",
            "  Downloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.31.0\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers==0.13.3\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.21.0) (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.23.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate==0.21.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.21.0) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.21.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.21.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate==0.21.0) (1.3.0)\n",
            "Installing collected packages: tokenizers, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, transformers, nvidia-cusolver-cu12, accelerate\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "Successfully installed accelerate-0.21.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 tokenizers-0.13.3 transformers-4.31.0\n",
            "Collecting bitsandbytes==0.40.0\n",
            "  Downloading bitsandbytes-0.40.0-py3-none-any.whl (91.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.9/91.9 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops==0.6.1\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes, einops\n",
            "Successfully installed bitsandbytes-0.40.0 einops-0.6.1\n",
            "Collecting xformers==0.0.22.post7\n",
            "  Downloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl (211.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.22.post7) (1.25.2)\n",
            "Collecting torch==2.1.0 (from xformers==0.0.22.post7)\n",
            "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.0.106)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->xformers==0.0.22.post7)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->xformers==0.0.22.post7) (12.1.105)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0->xformers==0.0.22.post7)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->xformers==0.0.22.post7) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->xformers==0.0.22.post7) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->xformers==0.0.22.post7) (1.3.0)\n",
            "Installing collected packages: triton, nvidia-nccl-cu12, torch, xformers\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.20.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.20.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.20.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.1.0 which is incompatible.\n",
            "torchtext 0.18.0 requires torch>=2.3.0, but you have torch 2.1.0 which is incompatible.\n",
            "torchvision 0.18.0+cu121 requires torch==2.3.0, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-nccl-cu12-2.18.1 torch-2.1.0 triton-2.1.0 xformers-0.0.22.post7\n",
            "Collecting langchain==0.1.4\n",
            "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain==0.1.4)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain==0.1.4)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain==0.1.4)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain==0.1.4)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain==0.1.4)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.1.4) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.1.4) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.4)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain==0.1.4)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain==0.1.4)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain==0.1.4)\n",
            "  Downloading langchain_community-0.0.37-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.36-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.35-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.32-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.31-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.0.30-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.28-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.27-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.26-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.24-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.23-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.22-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.16 (from langchain==0.1.4)\n",
            "  Downloading langchain_core-0.1.51-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.50-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.49-py3-none-any.whl (303 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.0/303.0 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.48-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.47-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.46-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.3/291.3 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.43-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.1/289.1 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.41-py3-none-any.whl (278 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.4/278.4 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.40-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.8/276.8 kB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_core-0.1.39-py3-none-any.whl (276 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.6/276.6 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.38-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.2/279.2 kB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.37-py3-none-any.whl (274 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.6/274.6 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.36-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.9/273.9 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.35-py3-none-any.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.0/273.0 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.34-py3-none-any.whl (271 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.6/271.6 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain==0.1.4) (3.7.1)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.31-py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.8/258.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.9/256.9 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.29-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.6/252.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.27-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.8/250.8 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.26-py3-none-any.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.4/246.4 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/242.1 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.24-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.3/241.3 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain==0.1.4)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2,>=0.1.16->langchain==0.1.4)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.4) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.4) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.1.4) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.1.4) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.1.4) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.4) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.16->langchain==0.1.4) (1.2.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.1.4)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.1.4 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 marshmallow-3.21.3 mypy-extensions-1.0.0 packaging-23.2 typing-inspect-0.9.0\n",
            "Collecting faiss-gpu==1.7.1.post3\n",
            "  Downloading faiss_gpu-1.7.1.post3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (90.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.1/90.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.1.post3\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers<5.0.0,>=4.34.0 (from sentence_transformers)\n",
            "  Downloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.5.40)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2024.5.15)\n",
            "Collecting tokenizers<0.20,>=0.19 (from transformers<5.0.0,>=4.34.0->sentence_transformers)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: tokenizers, transformers, sentence_transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.13.3\n",
            "    Uninstalling tokenizers-0.13.3:\n",
            "      Successfully uninstalled tokenizers-0.13.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.31.0\n",
            "    Uninstalling transformers-4.31.0:\n",
            "      Successfully uninstalled transformers-4.31.0\n",
            "Successfully installed sentence_transformers-3.0.1 tokenizers-0.19.1 transformers-4.41.2\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate==0.21.0 transformers==4.31.0 tokenizers==0.13.3\n",
        "!pip install bitsandbytes==0.40.0 einops==0.6.1\n",
        "!pip install xformers==0.0.22.post7\n",
        "!pip install langchain==0.1.4\n",
        "!pip install faiss-gpu==1.7.1.post3\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtklO7A21_BZ",
        "outputId": "075afb33-92a8-4704-96c8-e790ad85630e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.21.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Bh3hAtxjCcsh",
        "outputId": "143949dd-3a79-4456-8c74-c35c921237e3"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'nvidia' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-bc6386d60349>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnvidia\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msmi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'nvidia' is not defined"
          ]
        }
      ],
      "source": [
        "nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4438330e92d0418487c2b2065c2f341b",
            "51c3cc01b3df45c7bcd0d3e12744f537",
            "ceb938e99c10411ab8476a7e63044260",
            "059b6110348245e283ad6aaa40e6da38",
            "60a2bc0097324945acea3cde96d2dc96",
            "3bba47b698fd42708cd8496e60742765",
            "dca76af6553a479aadd693b9b598f417",
            "3f1a2a924e1b44dc80e564e748d34f0b",
            "ba7d7168013147eb9b5734b5cd9d729b",
            "062391de48f84294ad18970cfbef394e",
            "dbbc7427edd74c3cab3aae38f0b4fd96",
            "1b140209579443679b5a9b96901fa431",
            "949bd51c4cf24b52aaf278e28cb6111e",
            "b284cc4dd1ae4fa7b48c9e9eb18dc1ff",
            "1ae8e066fe8f4120a3cee7a5114322a8",
            "564af02f1fcb4401b7238bde01d663a2",
            "5e3cb1a82a284cfa9480535b13595fd6",
            "71a2054a7a5647e692b0ec5fec482527",
            "2a7726e898b841aea317711d7c85bd86",
            "cac6424fdd12428aa71dd5a1607b1e65",
            "e9b0710c38f24363ac74e51b4e97b3f3",
            "0da22bcd67e041e7987d553f9591b398",
            "65328ee92efb4641a036618f13413085",
            "fa57ad9594694a5dac2f1ea2558feade",
            "349295b4f4714f1abc12c201deb1463d",
            "7674f67efe5e4e9792a6f203321cf7a3",
            "ecb0a1d72e33422fb2fe6f2bdd631ee0",
            "caa5f169339b4a7fb1dd0e0be3491a76",
            "75dce7e80c9e43f8b55cecffcc411bd8",
            "cefd600dac0d4489a1aa4e3c50038523",
            "615be846d9704b3fa1d3e4234e9d502e",
            "0232c7e7b38242cd8063dfb7fe7b7e47",
            "26be670ca97e4829bd423aa2eb37bbc5",
            "8f61aa0524124b2e8f2967fe3f731bfb",
            "ee8fb93e3cea4882b8fb2abdf6b414f9",
            "dbc4b9f3773b4f438d5d6c1bc4dd8740",
            "f930dcf4fb8a421eab64015c5b23e803",
            "56468ab459d94fc5a4d59c18009bf57a",
            "edec55794ad64ebbbebce905f902ae72",
            "677aaeea8c8f43db95688473b8103886",
            "d06ab40bf2a54eb1bdb35bca753ec781",
            "1f528ae02def43e1950bddcd1cb9a641",
            "f3e9332ed5704300870dbbe267a99183",
            "a9cfeebf8de1492c83ba2229c8060f3a",
            "8484680170714542a791a05f7a0f8764",
            "09ccfb6cee5e4860984e73317e08aad7",
            "fd5580a3a1ff4517bf43ac4bfd0e94d4",
            "ca8b680c674d464e87a97c9ec0c4a22c",
            "4efb7169643a4784aa71a5c3c52c11c4",
            "7b41743705004637a4416d24b8fa03bb",
            "36d8c5bcb6094064b1e9bc6a90bc533e",
            "547b321336a04724ab4b6b74981a9867",
            "fd96d8091e2a4ea18c83ef5ebe5acae5",
            "d9005049d9934b66bd83d132d14cb83a",
            "9921825ec6ac4b8a9260b1c08cced51b",
            "a71ba1c858ad4dd2baa2b976f8bcc2f3",
            "c69484ed04c04dc4a6836c77c7a5cfab",
            "9cd5bd31b6314c8fb3fb90d9ab029e70",
            "19e5d5e111514ab184c4e23d0b6791cd",
            "eafcc6cc642a4daf97df9bef9b477f3e",
            "c591285f6fb5427698a63f6ff29d7359",
            "7677a492f8f54215b96ed8414a2732d1",
            "b7cef0e7c76c4374bce02c39e4ec2c68",
            "1e5f6fd5c0dc4342b9222ee0dc1ba6b1",
            "87a0eb798226426c9066c61edcaa405d",
            "c609a0f705c64a47ac92446fdf796232",
            "018287b893964e599a490f07e9b7fc87",
            "1efa76769d054bc88a4ff516201a1978",
            "b166d53a90d345a7965db0765062b861",
            "07f276fb84d647ee87fac044197c29cb",
            "3187a22d6c974ebda75c05616ac7b2eb",
            "8233432eda4e4be693daddc7bef61b76",
            "20c482ef6f3745a180fb4b00226e7d95",
            "7f03dcc044d7457c9b14c2dc1eb4dcfe",
            "49d96019799244b580eb88517b5391a5",
            "19f48dea823a41aea9ce53924251ad9c",
            "48011b80edcb4bd88f0a302dbe0ef801",
            "0b9baba8021d479f852d461a78d7de7f",
            "f7e68d7bf7e1494b8b1685db76bc8cd0",
            "62a9841e6284419a98781766ae0c60fe",
            "aacd4faf908d4b40b69592721adf9833",
            "85824a9e82324349a4b291e695da4bec",
            "e023dcdd6f914daaa5e61d584427f1aa",
            "ec429e184ce447699181944cf00237d0",
            "29b3220f08c041f8aa2c978798459712",
            "72e5c5adfc8f442a965ed542541b6c8f",
            "c8e780eab42e48b5b882ca4711d88590",
            "9e613de756054f3c8f9d5bf3d5618881"
          ]
        },
        "id": "Kg7XsrLxgdtj",
        "outputId": "77fa5d32-ae7d-44f0-95ef-1faaf262304b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py:919: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4438330e92d0418487c2b2065c2f341b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===================================BUG REPORT===================================\n",
            "Welcome to bitsandbytes. For bug reports, please run\n",
            "\n",
            "python -m bitsandbytes\n",
            "\n",
            " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
            "================================================================================\n",
            "bin /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda122.so\n",
            "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching in backup paths...\n",
            "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
            "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
            "CUDA SETUP: Detected CUDA version 122\n",
            "CUDA SETUP: Loading binary /usr/local/lib/python3.10/dist-packages/bitsandbytes/libbitsandbytes_cuda122.so...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: /usr/lib64-nvidia did not contain ['libcudart.so', 'libcudart.so.11.0', 'libcudart.so.12.0'] as expected! Searching further paths...\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/sys/fs/cgroup/memory.events /var/colab/cgroup/jupyter-children/memory.events')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('8013'), PosixPath('//172.28.0.1'), PosixPath('http')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('--logtostderr --listen_host=172.28.0.12 --target_host=172.28.0.12 --tunnel_background_save_url=https'), PosixPath('//colab.research.google.com/tun/m/cc48301118ce562b961b3c22d803539adc1e0c19/gpu-t4-s-2kev7bzybcgwq --tunnel_background_save_delay=10s --tunnel_periodic_background_save_frequency=30m0s --enable_output_coalescing=true --output_coalescing_required=true')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/env/python')}\n",
            "  warn(msg)\n",
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//ipykernel.pylab.backend_inline'), PosixPath('module')}\n",
            "  warn(msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1b140209579443679b5a9b96901fa431"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65328ee92efb4641a036618f13413085"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f61aa0524124b2e8f2967fe3f731bfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8484680170714542a791a05f7a0f8764"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a71ba1c858ad4dd2baa2b976f8bcc2f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "018287b893964e599a490f07e9b7fc87"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b9baba8021d479f852d461a78d7de7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda:0\n"
          ]
        }
      ],
      "source": [
        "from torch import cuda, bfloat16\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model_id = 'mistralai/Mistral-7B-Instruct-v0.2'\n",
        "\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# set quantization configuration to load large model with less GPU memory\n",
        "# this requires the `bitsandbytes` library\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")\n",
        "\n",
        "# begin initializing HF items, you need an access token\n",
        "hf_auth = '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'\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto',\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "\n",
        "# enable evaluation mode to allow model inference\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded on {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200,
          "referenced_widgets": [
            "9b996ff2d85748789bf35f259ad548b9",
            "0a70b170af634fd5a13e026c9550a012",
            "ae76ddd00b5a4170ab7da7141dfff6c5",
            "3ff7332c01b84bd9b7252265452cc5d0",
            "e8449f96a6b44ac5af3bb47c627a2289",
            "e0080a71f9b647449930684024ed4798",
            "c1e16ee7bd574b5b8e1da6a8f5b90f2d",
            "8d01e1ce52834d4c995f5b073fa15957",
            "01c887377fcf4fcda4828d9f08e12d2c",
            "17d6218df09c42ca92005221f0acc4d0",
            "c0e412755d1747be9c8d929c192211d2",
            "e8cd2efe959e47b5a7cdb305f6441f6b",
            "7b72a7e054d0491b960837213b374624",
            "facfb0356def4006904320c1c1e8dce3",
            "5399e83429304684bd21b0f34c643020",
            "597c40672b62400691a11fbd0d836b46",
            "4da007444db540c99d12d8b1f7f760d2",
            "d4c48c261c224f3bb5a0021a30a84e0e",
            "c78a47af4cee476593919c8de27be225",
            "421ec1aff05e4bc88d4a2e86689ff3a6",
            "1901b53c62154a068fd996626a86fbdb",
            "4abacc022b2c4216867439a6f2704ac8",
            "fb8841e371e34a6ba9f8c4126906ede5",
            "e827dbd3517743b89c556e59aa02bc73",
            "2bbe9b161d3d45f891238d734bf4b5a8",
            "5f874e839ae94f92b023e277450396f2",
            "07e2a8de94f14090911aa35958ee0f29",
            "17c869d51c6140cabb4b9d73373f7c17",
            "b92f8bf5dad949389b4274315a8eb19e",
            "19169d9879c54d418744ffcbed8aa9dc",
            "4cf634f4dd65441d9b6028c0e4266bdb",
            "c048d07c456740859b12ebc96a34540e",
            "78b8e8026fd24c27a91d7daa2307746d",
            "51370173c9a246c1b67a14f7fe8a83cc",
            "ea8415516d53443a8494b1e0d87792ac",
            "5a73ad2306364a5cab36ed222af3a2b4",
            "c61374c99f564406a19e643a8d23f14a",
            "a3ff59130723471baf9313f859b72ae4",
            "9e8997f9c8ca4d8caa6c75b76666ab6c",
            "2e106ff1e3194845b51c4ba9fa82fe85",
            "04b82f7fbc034efd81628b1e2901a6b8",
            "ee4ae716f03046fd91a4a75ab9e4ac19",
            "0868f608913c4707ad94684af0940b4e",
            "67ea19b8ca8f48b98f86f4457a537de6"
          ]
        },
        "id": "1r1JZIEGgvCZ",
        "outputId": "b9813619-622c-46fd-d74e-40d587cd0107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b996ff2d85748789bf35f259ad548b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e8cd2efe959e47b5a7cdb305f6441f6b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb8841e371e34a6ba9f8c4126906ede5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51370173c9a246c1b67a14f7fe8a83cc"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UodXIgrg-hA",
        "outputId": "b6ffbcfc-7e8f-4cfc-b011-fd150acb75c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 28705, 13, 28769, 6366, 28747], [1, 28705, 13, 13940, 28832, 13]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "stop_list = ['\\nHuman:', '\\n```\\n']\n",
        "\n",
        "stop_token_ids = [tokenizer(x)['input_ids'] for x in stop_list]\n",
        "stop_token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_keiKlxig_TI",
        "outputId": "3b6dffb4-1151-492a-b58c-b666ea0b5bed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([    1, 28705,    13, 28769,  6366, 28747], device='cuda:0'),\n",
              " tensor([    1, 28705,    13, 13940, 28832,    13], device='cuda:0')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "stop_token_ids = [torch.LongTensor(x).to(device) for x in stop_token_ids]\n",
        "stop_token_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xG-rGnw_hCi9"
      },
      "outputs": [],
      "source": [
        "from transformers import StoppingCriteria, StoppingCriteriaList,pipeline\n",
        "\n",
        "# define custom stopping criteria object\n",
        "class StopOnTokens(StoppingCriteria):\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop_ids in stop_token_ids:\n",
        "            if torch.eq(input_ids[0][-len(stop_ids):], stop_ids).all():\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "stopping_criteria = StoppingCriteriaList([StopOnTokens()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NElOadjZhGeQ"
      },
      "outputs": [],
      "source": [
        "generate_text = transformers.pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,#  These are specifying the pretrained transformer model and associated tokenizer to use for text generation.\n",
        "    return_full_text=True,  # langchain expects the full text\n",
        "    task='text-generation',\n",
        "    # we pass model parameters here too\n",
        "    stopping_criteria=stopping_criteria,  # without this model rambles during chat\n",
        "    temperature=0.1,  #  Controls randomness of the generated text. Lower values make it more deterministic.\n",
        "    max_new_tokens=1024,  # max number of tokens to generate in the output\n",
        "    repetition_penalty=1.1  # without this output begins repeating\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "560MPyoY-kmR"
      },
      "outputs": [],
      "source": [
        "generate_text = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    return_full_text=True,\n",
        "    task='text-generation',\n",
        "    stopping_criteria=stopping_criteria,\n",
        "    temperature=0.7,  #  for more creative generation\n",
        "    max_new_tokens=1500,\n",
        "    # min_new_tokens=1000,\n",
        "    repetition_penalty=1.2  # reduce repetition\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qe6hJGnoqhv"
      },
      "outputs": [],
      "source": [
        "pip install --upgrade langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrp9Bs3utb-3",
        "outputId": "4b91b50d-1444-4f50-9416-5437a22cb0ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.0.20)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.6)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.23)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.0.87)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.21->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.21->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.21->langchain_community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.21->langchain_community) (2.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.21->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.21->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.21->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.21->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.21->langchain_community) (2.18.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "pip install langchain_community\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3IDBWG-dUHE",
        "outputId": "c83f94c4-c1db-456e-8053-87c5028f6169"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First part generated by LLM: \n",
            "---\n",
            "\n",
            "Emma Carter, a seasoned archaeologist with sun-streaked hair and eyes as sharp as her trowel, stood before the crumbling ruins of an ancient temple nestled deep within the Amazon rainforest. Her heart pounded with excitement as she surveyed the overgrown site, her mind racing with possibilities. Rumors had reached her of a long-lost artifact said to grant its possessor eternal life - the fabled Elixir of Immortality.\n",
            "\n",
            "As she began unpacking her gear from the backpack slung across her shoulders, a rustling sound echoed through the dense foliage nearby. She whipped around, her hand instinctively reaching for the worn leather holster at her side where her trusted Colt Python revolver lay hidden. But it was only Raj Patel, her loyal sidekick, emerging from the undergrowth, a worried expression etched onto his face.\n",
            "\n",
            "\"What's wrong?\" asked Emma, lowering her weapon.\n",
            "\n",
            "Raj looked uneasy. \"We have company.\" He pointed towards a group of men clad in ragged clothing, their faces obscured by bandanas, approaching the campsite. They carried machetes and rifles, their intent unmistakable.\n",
            "\n",
            "Emma cursed under her breath. These weren't just ordinary bandits; they were mercenaries led by none other than Victor Steele, a notorious treasure hunter infamous for his ruthlessness and cunning. Steele had been after the Elixir for years, and he wouldn't hesitate to kill anyone standing in his way.\n",
            "\n",
            "With no time to waste, Emma quickly gathered her team together. Raj, a tech-savvy historian, had proven himself indispensable during their previous adventures. And then there was Alex Turner, a local guide whose knowledge of the jungle proved crucial when navigating through treacherous terrain. Together, they formed an unlikely trio determined to protect the priceless relic from falling into the wrong hands.\n",
            "\n",
            "They hurriedly packed up their belongings and prepared to leave. As they retreated deeper into the forest, they could hear the growing roar of engines behind them – the telltale sign of Steele's motorboats closing in fast.\n",
            "\n",
            "Suddenly, a shrill cry pierced the air. It came from above, sending chills down everyone's spine. A helicopter loomed overhead, its searchlight illuminating the canopy below. In the cockpit sat Victor Steele himself, sneering maliciously as he spotted the fleeing figures beneath him.\n",
            "\n",
            "\"Looks like we've got ourselves a chase scene,\" remarked Emma grimly, adjusting her goggles. \"Let's make it worth their while!\"\n",
            "\n",
            "Together, the three companions sprinted through the thick vegetation, dodging fallen trees and leaping over ravines. Their pursuers weren't far behind, their engines growling ominously as they closed the gap between them.\n",
            "\n",
            "Just as hope seemed lost, a clearing appeared ahead. There, nestled among towering palms, stood another ancient ruin. This one bore intricate carvings depicting scenes of gods and mythical creatures. Could it be the resting place of the Elixir?\n",
            "\n",
            "Without pausing for breath, they rushed inside, their hearts pounding with anticipation. Inside, they found a chamber filled with golden idols and precious gemstones. At the center stood a pedestal upon which rested a small vial made of pure crystal. Its surface shimmered with an ethereal glow, reflecting the flickering torchlight.\n",
            "\n",
            "Steele's voice boomed through the entrance, sending tremors through the ground beneath their feet. \"Hand it over, Carter! I won't ask again!\"\n",
            "\n",
            "But even as danger lurked outside, Emma knew what she must do. With determination burning in her eyes, she stepped forward, holding out the vial towards the sky. \"This isn't about immortality, Steele. It's about legacy...about leaving something behind that lasts longer than us all.\"\n",
            "\n",
            "Her defiant stance took Steele aback, giving her teammates enough time to prepare a surprise counterattack. Suddenly, the room erupted in chaos as torches ignited the vast cache of explosives hidden within the walls.\n",
            "\n",
            "In the ensuing explosion, both sides were obliterated, leaving nothing but ash and rubble behind. Amidst the destruction, however, one thing remained untouched – the crystalline vial containing the Elixir of Immortality.\n",
            "\n",
            "And so, as dawn broke over the smoldering ruins, Emma, Raj, and Alex continued their journey, knowing that they had saved not only themselves but also the world from the clutches of a madman. For now, the secret of eternal life would remain hidden, waiting for those worthy enough to discover it.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "# Define the first LLM\n",
        "llm_first = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# Define the prompt template for the first LLM\n",
        "template_first = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula is a writing guide created by Lester Dent, a prolific pulp fiction writer best known for his work on the \"Doc Savage\" series. Dent's formula provides a structured approach to crafting engaging and action-packed stories. Here is a brief overview of the formula:\n",
        "\n",
        "Introduction:\n",
        "Introduce the hero and the central problem or conflict.\n",
        "Set up a situation that hooks the reader's interest immediately.\n",
        "First Quarter:\n",
        "The hero tries to solve the problem.\n",
        "Introduce complications and obstacles that thwart the hero's initial attempts.\n",
        "Introduce other key characters (both allies and antagonists).\n",
        "End with a twist or a surprising development.\n",
        "\n",
        "Characters:\n",
        "- Hero: Emma Carter, a fearless archaeologist with a knack for solving ancient mysteries.\n",
        "- Villain: Victor Steele, a ruthless treasure hunter obsessed with finding the legendary Elixir of Immortality.\n",
        "- Sidekick: Raj Patel, a tech-savvy historian assisting Emma.\n",
        "- Victim: Dr. Elena Gomez, a renowned historian murdered while researching the Elixir.\n",
        "- Witness: Alex Turner, a local guide who witnessed the crime.\n",
        "\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "Based on this formula, your task is to generate exactly the first 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "prompt_first = PromptTemplate.from_template(template_first)\n",
        "\n",
        "# Generate the initial story outline\n",
        "initial_result = llm_first(prompt_first.format())\n",
        "print(\"First part generated by LLM:\", initial_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHPsKWOpffCP",
        "outputId": "d4362d3d-c965-4e34-a137-9c9f9f7bea3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Second part generated by LLM: \n",
            "---\n",
            "\n",
            "As the sun rose higher in the sky, casting dappled light through the emerald leaves, our intrepid heroes found solace in the quietude of the forest. The adrenaline rush of their narrow escape still coursed through their veins, yet they knew they couldn't afford to rest on their laurels.\n",
            "\n",
            "First and foremost, they needed to ensure their safety. Emma suggested setting up camp further away from civilization, preferably near a water source. After hours of careful navigation, they stumbled upon a secluded spot beside a babbling brook. The lush greenery provided ample cover, making it an ideal location for their temporary shelter.\n",
            "\n",
            "While Raj busied himself with collecting firewood and preparing food, Emma and Alex discussed their next move. They agreed that returning to civilization wasn't an option; word of their encounter with Victor Steele would surely spread, putting them in grave danger. Instead, they decided to continue searching for the remaining pieces of the legendary Crystal Skull, rumored to hold the key to unlocking the true power of the Elixir.\n",
            "\n",
            "However, they soon realized that they lacked essential resources for such a prolonged expedition. They needed supplies, maps, and most importantly, information. To acquire these items, they planned to visit an old friend of Emma's – Dr. Marcus Thompson, a renowned anthropologist specializing in Mayan culture. His expertise might prove instrumental in helping them decipher cryptic texts related to the Crystal Skull.\n",
            "\n",
            "After bidding farewell to Raj, who chose to stay behind due to his vital role back at base, Emma and Alex embarked on their new quest. They traveled along winding rivers, scaled steep mountainsides, and braved treacherous jungle trails. Along the way, they encountered various obstacles, including wild animals, harsh weather conditions, and even hostile tribes. Yet, their resolve never wavered.\n",
            "\n",
            "One evening, as they huddled around a crackling campfire, they heard whispers of a legend passed down through generations. According to the tale, the final piece of the Crystal Skull was hidden deep within a sacred cave located high atop Mount Xibalba. This mountain was known for its volatile climate, characterized by frequent thunderstorms and lightning strikes.\n",
            "\n",
            "Despite the inherent risks involved, Emma saw an opportunity. If they managed to secure the Crystal Skull, they could potentially use its power to neutralize any potential threats against them. Armed with renewed vigor, they set off early the following morning, undeterred by the impending challenge.\n",
            "\n",
            "Days turned into weeks as they climbed the treacherous slopes of Mount Xibalba. Each step brought them closer to their goal, but each misstep threatened to send them plummeting to their demise. During their arduous climb, they faced numerous trials testing their courage, strength, and intellect.\n",
            "\n",
            "At one point, they encountered a particularly challenging puzzle involving a series of pressure plates embedded in the cavern wall. Solving it required precise timing and coordination. Failure meant triggering a deadly trapdoor leading to certain death. Drawing upon their combined skills, Emma and Alex worked tirelessly until finally, the hidden passageway opened up, revealing the inner sanctum of the cave.\n",
            "\n",
            "Breathless and exhilarated, they entered the dimly lit chamber. Before them lay the magnificent Crystal Skull, its facets gleaming in the faint glow emitted by luminescent fungi scattered throughout the room. Overwhelmed by emotion, they carefully lifted the priceless artifact, feeling its cool touch against their skin.\n",
            "\n",
            "Now armed with the complete Crystal Skull, they returned to their camp, eager to explore its secrets. However, little did they know, their greatest challenge yet awaited them. Unbeknownst to them, Victor Steele had survived the explosion and was hot on their trail.\n",
            "\n",
            "Determined to claim the Elixir for himself, Steele followed their every move, always staying just beyond reach. One night, as they settled down for the evening, they were ambushed by a large contingent of mercenaries sent by Steele. Outnumbered and outmatched, Emma and Alex fought valiantly, using every trick in their arsenal to keep their enemies at bay.\n",
            "\n",
            "Just when all hope seemed lost, a deafening roar echoed through the forest. From the darkness emerged Raj, having tracked their movements since their separation. Together, the trio launched a fierce counteroffensive, turning the tide of battle decisively in their favor. By dawn, the remnants of Steele's forces retreated, leaving our heroes victorious but battered and bruised.\n",
            "\n",
            "Having successfully thwarted Steele once more, they regrouped and devised a plan to safeguard the Elixir and the Crystal Skull. They decided to hide them in a remote location accessible only to select individuals sworn to protect them. Satisfied that their mission was accomplished, they bid farewell to each other, knowing that their lives would forever be intertwined in the annals of history.\n"
          ]
        }
      ],
      "source": [
        "# Define the second LLM\n",
        "llm_second = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# Define the prompt template for the second LLM\n",
        "template_second = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Second Quarter:\n",
        "Escalate the conflict and introduce additional problems for the hero.\n",
        "The hero faces greater challenges and setbacks.\n",
        "Include physical conflicts or action scenes.\n",
        "Introduce a major plot twist or revelation that complicates the hero's mission.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "prompt_second = PromptTemplate.from_template(template_second)\n",
        "\n",
        "# Generate the continuation of the story\n",
        "second_result = llm_second(prompt_second.format(first_part=initial_result))\n",
        "print(\"Second part generated by LLM:\", second_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fweWmOI3g1vZ",
        "outputId": "02ab14a8-0a38-4221-ebba-6a1a79050069"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Third part generated by LLM: \n",
            "---\n",
            "\n",
            "As the sun began to rise over the horizon, painting the sky in hues of orange and pink, Emma, Alex, and Raj shared a moment of silence, acknowledging the gravity of their victory. Their hearts beat steadily, mirroring the rhythm of the forest around them. Despite the relief that washed over them, they understood that their journey was far from over.\n",
            "\n",
            "The Elixir of Immortality and the Crystal Skull were powerful relics, coveted by many for reasons both noble and nefarious. They held immense potential, capable of changing the course of human history if used correctly. But in the wrong hands, they could bring about devastation and chaos.\n",
            "\n",
            "To prevent such an outcome, they resolved to find trustworthy guardians for these priceless artifacts. They spent days poring over ancient manuscripts, consulting scholars, and traveling to distant lands, seeking answers. Eventually, they discovered an order of monks living deep within the Himalayas, famed for their wisdom and dedication to preserving historical knowledge.\n",
            "\n",
            "These monks, known as the Keepers of Time, welcomed the trio warmly, recognizing the significance of their quest. After rigorous tests designed to assess their character and intentions, they were granted access to the Sacred Caverns, a network of subterranean tunnels housing countless relics and artifacts. Here, amidst the serene atmosphere, they entrusted the Elixir and the Crystal Skull to the care of the Keepers.\n",
            "\n",
            "However, their work didn't end there. The trio knew that there would always be those who sought to exploit the power of the Elixir and the Crystal Skull for personal gain. To combat this threat, they dedicated themselves to spreading awareness about the importance of responsible stewardship and ethical use of ancient knowledge.\n",
            "\n",
            "Over the years, they traveled extensively, sharing their experiences and insights with scholars, historians, and spiritual leaders worldwide. Through lectures, publications, and collaborative research projects, they inspired a new generation of guardians committed to protecting humanity's collective heritage.\n",
            "\n",
            "Meanwhile, news of their accomplishments reached far and wide, earning them accolades and recognition. Institutions offered them positions of authority, allowing them to establish academic departments focused on archaeology, cultural preservation, and sustainable exploration practices.\n",
            "\n",
            "Yet, despite their achievements, they remained humble, always remembering the lessons learned during their perilous adventure. They continued to live simply, dedicating their lives to the pursuit of knowledge and the protection of history.\n",
            "\n",
            "Word of their exploits eventually reached Victor Steele, who, bitter and resentful, hatched a new scheme. Realizing that direct confrontations with the trio had yielded minimal results, he decided to manipulate events from behind the shadows. Using his extensive network of contacts, he began funding various criminal organizations, fueling conflict and instability across continents.\n",
            "\n",
            "His ultimate objective was to create chaos and disorder, hoping that in the resulting confusion, he could seize control of the Elixir and the Crystal Skull. But Emma, Alex, and Raj were well aware of his machinations. Working closely with international law enforcement agencies, they dismantled his operations one by one, exposing his criminal empire bit by bit.\n",
            "\n",
            "Each successive blow weakened Steele, forcing him to adapt and evolve his tactics. But the trio refused to let up, relentlessly pursuing him until he was cornered in a remote jungle stronghold. In a climactic showdown, they confronted him personally, bringing an end to his reign of terror.\n",
            "\n",
            "With Steele defeated, peace gradually restored itself to the world. People celebrated the return of stability and security, grateful for the efforts of the trio. News of their triumphant conclusion to the saga reached every corner of the globe, inspiring awe and admiration.\n",
            "\n",
            "Reflecting on their incredible journey, Emma, Alex, and Raj marveled at how far they had come. They had started as ordinary individuals driven by curiosity and passion, but they had transformed into respected guardians of history and champions of ethical exploration. Their bond had grown stronger with each passing day, transcending friendship and solidifying into an unbreakable alliance.\n",
            "\n",
            "As they gazed at the stars twinkling above, they knew that their story was far from finished. New challenges would arise, new mysteries would need solving, and new adventures would call out to them. But whatever lay ahead, they were ready, united by their common purpose and bound by their unwavering commitment to preserve the rich tapestry of human history.\n"
          ]
        }
      ],
      "source": [
        "llm_third = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "template_third = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Third Quarter:\n",
        "The hero makes some progress towards solving the problem but faces significant adversity.\n",
        "Introduce new conflicts and obstacles.\n",
        "The hero encounters the main villain or a critical turning point in the story.\n",
        "End with a twist that puts the hero in an even worse situation.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "This is the second part of the story:\n",
        "{second_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "prompt_third = PromptTemplate.from_template(template_third)\n",
        "\n",
        "# Generate the next part of the story\n",
        "third_result = llm_third(prompt_third.format(first_part=initial_result, second_part=second_result))\n",
        "print(\"Third part generated by LLM:\", third_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI2OV0T6hdmO",
        "outputId": "587b2093-0479-4a20-fa95-2fa1992d8f90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final part generated by LLM: \n",
            "---\n",
            "\n",
            "As the sun began to dip below the horizon, casting elongated shadows across the jungle floor, the trio pressed onward, their spirits buoyed by the recent victory. Though Victor Steele had been vanquished, they knew that his defeat was merely a reprieve. The Elixir of Immortality and the Crystal Skull remained potent symbols of power, desired by many for nefarious purposes.\n",
            "\n",
            "Their journey home was fraught with challenges. They traversed treacherous terrains, battled ferocious wildlife, and navigated treacherous waters teeming with pirates and privateers. Yet, they remained resolute, drawing strength from their shared experiences and the knowledge that they were guardians of history.\n",
            "\n",
            "Upon their arrival at the Monastery of the Keepers of Time, they were greeted with open arms. The monks praised their valor and commended their selfless dedication to preserving the past for future generations. In gratitude, they bestowed upon Emma, Alex, and Raj the title of Honorary Guardians, granting them access to the monastery's vast library and archives.\n",
            "\n",
            "As they delved deeper into the troves of ancient knowledge, they discovered countless stories of civilizations long forgotten, tales of brave explorers who risked everything in pursuit of discovery, and accounts of legendary artifacts that shaped the course of history. Inspired by these narratives, they redoubled their efforts to promote ethical exploration practices and inspire a new generation of guardians.\n",
            "\n",
            "News of their exploits reached far and wide, capturing the imagination of people everywhere. Scholars, historians, and adventurers flocked to learn from them, drawn by their unique blend of experience, wisdom, and passion. They established educational programs aimed at fostering a love for history and encouraging young minds to seek knowledge and understanding.\n",
            "\n",
            "Throughout their travels, they encountered adversity in unexpected forms. Some criticized their methods, arguing that the pursuit of knowledge justified any means necessary. Others accused them of being gatekeepers, hoarding valuable information for themselves. But Emma, Alex, and Raj remained unfazed, refusing to compromise their principles.\n",
            "\n",
            "Instead, they embraced these challenges as opportunities to engage in thoughtful discourse and foster meaningful dialogue. They recognized that change was inevitable and that progress often demanded difficult choices. So, they adapted their approach, focusing on collaboration rather than competition, and emphasizing the importance of respecting diverse perspectives.\n",
            "\n",
            "As the years passed, they watched as their students grew into brilliant scholars and passionate advocates for historical preservation. They witnessed the establishment of institutions dedicated to promoting ethical exploration practices and supporting researchers in their endeavors. And they felt a sense of pride knowing that their influence extended beyond their immediate circle.\n",
            "\n",
            "But even as they reveled in their accomplishments, they knew that their work was far from done. New threats emerged, threatening the very fabric of history. False histories propagated lies and distorted truths, sowing seeds of division and strife. Myths and legends were twisted to serve political agendas, blurring the line between fact and fiction.\n",
            "\n",
            "Undaunted, they continued their mission, working tirelessly to debunk falsehoods and restore accuracy to historical records. They collaborated with experts from various fields, combining their respective areas of expertise to tackle complex issues. And they mentored the next generation of guardians, ensuring that their legacy lived on.\n",
            "\n",
            "Amidst the turmoil of a rapidly changing world, they remained steadfast in their convictions. They believed that the power of knowledge could bridge divides, heal wounds, and build bridges between communities. And they knew that their duty was to help others see the same potential.\n",
            "\n",
            "So, they traveled the world, sharing their insights and experiences, and inspiring others to join their cause. They spoke at conferences, published papers, and engaged in public debates, championing the importance of accurate historical record keeping and ethical exploration practices.\n",
            "\n",
            "Eventually, their names became synonymous with integrity, scholarship, and a deep appreciation for the value of history. They left an indelible mark on the world, inspiring generations to follow in their footsteps.\n",
            "\n",
            "But even as they aged, they never lost sight of their original goals. They continued to push boundaries, exploring new frontiers and expanding their horizons. And though they faced new challenges, they met them head-on, drawing inspiration from their past experiences and the knowledge that they were part of a larger narrative.\n",
            "\n",
            "As the sun set on their remarkable lives, they reflected on their journey, marveling at how far they had come. They had started as curious souls driven by a desire to understand the world around them. Now, they were revered guardians of history, champions of truth, and architects of a better tomorrow.\n",
            "\n",
            "And as they drifted off into the sweet embrace of sleep, they knew that their story was far from over. New chapters awaited them, filled with endless possibilities and exciting discoveries. And they looked forward to facing these challenges, confident in the knowledge that they were not alone.\n",
            "\n",
            "For they were part of a grand tradition, a proud legacy that stretched back millennia. They were custodians of the past, bearers of the torch passed down through generations. And they knew that their actions today would shape the future, guiding the next wave of explorers and scholars as they ventured forth into the unknown.\n",
            "\n",
            "So, they closed their eyes, content in the knowledge that their story was far from over. They dreamed of new adventures, of uncharted territories, and of untold stories waiting to be discovered. And they smiled, knowing that they would wake up tomorrow, ready to face another day filled with wonder and possibility.\n"
          ]
        }
      ],
      "source": [
        "llm_fourth = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# Define the prompt template for the fourth LLM\n",
        "template_fourth = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Final Quarter:\n",
        "The hero faces the greatest challenges and is pushed to their limits.\n",
        "All mysteries and plot threads are resolved.\n",
        "The hero uses their skills, intelligence, and bravery to overcome the final obstacles.\n",
        "End with a final twist or surprise that concludes the story in a satisfying way.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "This is the second part of the story:\n",
        "{second_part}\n",
        "\n",
        "This is the third part of the story:\n",
        "{third_part}\n",
        "\n",
        "Based on this formula, your task is to generate the final 1500 words of the story which is the last quarter of the story so you should end the story in this chapter,the generated text should be in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "prompt_fourth = PromptTemplate.from_template(template_fourth)\n",
        "\n",
        "# Generate the final part of the story\n",
        "fourth_result = llm_fourth(prompt_fourth.format(first_part=initial_result, second_part=second_result, third_part=third_result))\n",
        "print(\"Final part generated by LLM:\", fourth_result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0hwchS5HwJ5",
        "outputId": "f665a7da-43ba-449a-c673-0c52d7318849"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.0.1 (from gradio)\n",
            "  Downloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=5d4857ba229b150365eb113af3d69790de9341d2f9fadf5a5dd4521098462e23\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.36.1 gradio-client-1.0.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.4 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.8 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RBeu-KN1Q6mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "# Define the LLMs\n",
        "llm_first = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm_second = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm_third = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm_fourth = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# Define the prompt templates for each LLM\n",
        "template_first = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula is a writing guide created by Lester Dent, a prolific pulp fiction writer best known for his work on the \"Doc Savage\" series. Dent's formula provides a structured approach to crafting engaging and action-packed stories. Here is a brief overview of the formula:\n",
        "\n",
        "Introduction:\n",
        "Introduce the hero and the central problem or conflict.\n",
        "Set up a situation that hooks the reader's interest immediately.\n",
        "First Quarter:\n",
        "The hero tries to solve the problem.\n",
        "Introduce complications and obstacles that thwart the hero's initial attempts.\n",
        "Introduce other key characters (both allies and antagonists).\n",
        "End with a twist or a surprising development.\n",
        "\n",
        "Characters:\n",
        "- Hero: {hero}\n",
        "- Villain: {villain}\n",
        "- Sidekick: {sidekick}\n",
        "- Victim: {victim}\n",
        "- Witness: {witness}\n",
        "\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "Based on this formula, your task is to generate exactly the first 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "template_second = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Second Quarter:\n",
        "Escalate the conflict and introduce additional problems for the hero.\n",
        "The hero faces greater challenges and setbacks.\n",
        "Include physical conflicts or action scenes.\n",
        "Introduce a major plot twist or revelation that complicates the hero's mission.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "template_third = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Third Quarter:\n",
        "The hero makes some progress towards solving the problem but faces significant adversity.\n",
        "Introduce new conflicts and obstacles.\n",
        "The hero encounters the main villain or a critical turning point in the story.\n",
        "End with a twist that puts the hero in an even worse situation.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "This is the second part of the story:\n",
        "{second_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "template_fourth = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Final Quarter:\n",
        "The hero faces the greatest challenges and is pushed to their limits.\n",
        "All mysteries and plot threads are resolved.\n",
        "The hero uses their skills, intelligence, and bravery to overcome the final obstacles.\n",
        "End with a final twist or surprise that concludes the story in a satisfying way.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "This is the second part of the story:\n",
        "{second_part}\n",
        "\n",
        "This is the third part of the story:\n",
        "{third_part}\n",
        "\n",
        "Based on this formula, your task is to generate the final 1500 words of the story which is the last quarter of the story so you should end the story in this chapter. The generated text should be in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "# Function to combine all parts into one text\n",
        "def combine_story_parts(*parts):\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "# Function to generate the first part\n",
        "def generate_first_part(hero, villain, sidekick, victim, witness):\n",
        "    prompt_first = PromptTemplate.from_template(template_first)\n",
        "    first_result = llm_first(prompt_first.format(hero=hero, villain=villain, sidekick=sidekick, victim=victim, witness=witness))\n",
        "    return first_result\n",
        "\n",
        "# Function to generate the second part\n",
        "def generate_second_part(first_part):\n",
        "    prompt_second = PromptTemplate.from_template(template_second)\n",
        "    second_result = llm_second(prompt_second.format(first_part=first_part))\n",
        "    return second_result\n",
        "\n",
        "# Function to generate the third part\n",
        "def generate_third_part(first_part, second_part):\n",
        "    prompt_third = PromptTemplate.from_template(template_third)\n",
        "    third_result = llm_third(prompt_third.format(first_part=first_part, second_part=second_part))\n",
        "    return third_result\n",
        "\n",
        "# Function to generate the final part\n",
        "def generate_final_part(first_part, second_part, third_part):\n",
        "    prompt_fourth = PromptTemplate.from_template(template_fourth)\n",
        "    fourth_result = llm_fourth(prompt_fourth.format(first_part=first_part, second_part=second_part, third_part=third_part))\n",
        "    return fourth_result\n",
        "\n",
        "# Function to combine all parts and generate the full story\n",
        "def generate_full_story(hero, villain, sidekick, victim, witness, first_part, second_part, third_part):\n",
        "    # Generate the final part\n",
        "    final_part = generate_final_part(first_part, second_part, third_part)\n",
        "\n",
        "    # Combine all parts\n",
        "    full_story = combine_story_parts(first_part, second_part, third_part, final_part)\n",
        "    return full_story\n",
        "\n",
        "# Define the Gradio interface\n",
        "with gr.Blocks() as interface:\n",
        "    gr.Markdown(\"# Story Generator\")\n",
        "    gr.Markdown(\"Generate a complete story based on the Lester Dent Pulp Paper formula.\")\n",
        "\n",
        "    with gr.Row():\n",
        "        hero_input = gr.Textbox(label=\"Hero\")\n",
        "        villain_input = gr.Textbox(label=\"Villain\")\n",
        "        sidekick_input = gr.Textbox(label=\"Sidekick\")\n",
        "        victim_input = gr.Textbox(label=\"Victim\")\n",
        "        witness_input = gr.Textbox(label=\"Witness\")\n",
        "        generate_first = gr.Button(\"Generate First Part\")\n",
        "\n",
        "    first_part_output = gr.Textbox(label=\"First Part\", lines=10)\n",
        "\n",
        "    with gr.Row():\n",
        "        generate_second = gr.Button(\"Generate Second Part\")\n",
        "        first_part_modified = gr.Textbox(label=\"Modified First Part\", lines=10)\n",
        "\n",
        "    second_part_output = gr.Textbox(label=\"Second Part\", lines=10)\n",
        "\n",
        "    with gr.Row():\n",
        "        generate_third = gr.Button(\"Generate Third Part\")\n",
        "        second_part_modified = gr.Textbox(label=\"Modified Second Part\", lines=10)\n",
        "\n",
        "    third_part_output = gr.Textbox(label=\"Third Part\", lines=10)\n",
        "\n",
        "    with gr.Row():\n",
        "        generate_final = gr.Button(\"Generate Final Part\")\n",
        "        third_part_modified = gr.Textbox(label=\"Modified Third Part\", lines=10)\n",
        "\n",
        "    final_part_output = gr.Textbox(label=\"Final Part\", lines=10)\n",
        "\n",
        "    generate_full = gr.Button(\"Generate Full Story\")\n",
        "    full_story_output = gr.Textbox(label=\"Full Story\", lines=20)\n",
        "\n",
        "    # Set up the interactions\n",
        "    generate_first.click(\n",
        "        fn=generate_first_part,\n",
        "        inputs=[hero_input, villain_input, sidekick_input, victim_input, witness_input],\n",
        "        outputs=[first_part_output]\n",
        "    )\n",
        "\n",
        "    generate_second.click(\n",
        "        fn=generate_second_part,\n",
        "        inputs=[first_part_output],\n",
        "        outputs=[second_part_output]\n",
        "    )\n",
        "\n",
        "    generate_third.click(\n",
        "        fn=generate_third_part,\n",
        "        inputs=[first_part_modified, second_part_output],\n",
        "        outputs=[third_part_output]\n",
        "    )\n",
        "\n",
        "    generate_final.click(\n",
        "        fn=generate_final_part,\n",
        "        inputs=[first_part_modified, second_part_modified, third_part_output],\n",
        "        outputs=[final_part_output]\n",
        "    )\n",
        "\n",
        "    generate_full.click(\n",
        "        fn=generate_full_story,\n",
        "        inputs=[hero_input, villain_input, sidekick_input, victim_input, witness_input, first_part_modified, second_part_modified, third_part_modified],\n",
        "        outputs=[full_story_output]\n",
        "    )\n",
        "\n",
        "# Launch the Gradio interface\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "QwXIHXB3Hq_r",
        "outputId": "4d93f249-4169-4284-c89c-c10443ddec41"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e7d162b625d8635874.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e7d162b625d8635874.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Hero: Emma Carter, a fearless archaeologist with a knack for solving ancient mysteries.\n",
        "- Villain: Victor Steele, a ruthless treasure hunter obsessed with finding the legendary Elixir of Immortality.\n",
        "- Sidekick: Raj Patel, a tech-savvy historian assisting Emma.\n",
        "- Victim: Dr. Elena Gomez, a renowned historian murdered while researching the Elixir.\n",
        "- Witness: Alex Turner, a local guide who witnessed the crime."
      ],
      "metadata": {
        "id": "ouvJT7xOKhPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the first part and let the user modify it.\n",
        "Generate the second part using the modified first part and let the user modify it.\n",
        "Generate the third part using the modified first and second parts and let the user modify it.\n",
        "Generate the final part using the modified first, second, and third parts and let the user modify it.\n",
        "Combine all parts into one final story."
      ],
      "metadata": {
        "id": "b_rORULK8aBO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GPFGp96J8Va1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_story_parts(*parts):\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "# Combine all parts of the story\n",
        "full_story = combine_story_parts(initial_result, second_result, third_result, fourth_result)\n",
        "print(\"Full story:\", full_story)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARwfJB63i6VE",
        "outputId": "e0d4a791-ff72-4dc9-c1ba-6b0cd713ed0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full story: \n",
            "---\n",
            "\n",
            "Emma Carter, a seasoned archaeologist with sun-streaked hair and eyes as sharp as her trowel, stood before the crumbling ruins of an ancient temple nestled deep within the Amazon rainforest. Her heart pounded with excitement as she surveyed the overgrown site, her mind racing with possibilities. Rumors had reached her of a long-lost artifact said to grant its possessor eternal life - the fabled Elixir of Immortality.\n",
            "\n",
            "As she began unpacking her gear from the backpack slung across her shoulders, a rustling sound echoed through the dense foliage nearby. She whipped around, her hand instinctively reaching for the worn leather holster at her side where her trusted Colt Python revolver lay hidden. But it was only Raj Patel, her loyal sidekick, emerging from the undergrowth, a worried expression etched onto his face.\n",
            "\n",
            "\"What's wrong?\" asked Emma, lowering her weapon.\n",
            "\n",
            "Raj looked uneasy. \"We have company.\" He pointed towards a group of men clad in ragged clothing, their faces obscured by bandanas, approaching the campsite. They carried machetes and rifles, their intent unmistakable.\n",
            "\n",
            "Emma cursed under her breath. These weren't just ordinary bandits; they were mercenaries led by none other than Victor Steele, a notorious treasure hunter infamous for his ruthlessness and cunning. Steele had been after the Elixir for years, and he wouldn't hesitate to kill anyone standing in his way.\n",
            "\n",
            "With no time to waste, Emma quickly gathered her team together. Raj, a tech-savvy historian, had proven himself indispensable during their previous adventures. And then there was Alex Turner, a local guide whose knowledge of the jungle proved crucial when navigating through treacherous terrain. Together, they formed an unlikely trio determined to protect the priceless relic from falling into the wrong hands.\n",
            "\n",
            "They hurriedly packed up their belongings and prepared to leave. As they retreated deeper into the forest, they could hear the growing roar of engines behind them – the telltale sign of Steele's motorboats closing in fast.\n",
            "\n",
            "Suddenly, a shrill cry pierced the air. It came from above, sending chills down everyone's spine. A helicopter loomed overhead, its searchlight illuminating the canopy below. In the cockpit sat Victor Steele himself, sneering maliciously as he spotted the fleeing figures beneath him.\n",
            "\n",
            "\"Looks like we've got ourselves a chase scene,\" remarked Emma grimly, adjusting her goggles. \"Let's make it worth their while!\"\n",
            "\n",
            "Together, the three companions sprinted through the thick vegetation, dodging fallen trees and leaping over ravines. Their pursuers weren't far behind, their engines growling ominously as they closed the gap between them.\n",
            "\n",
            "Just as hope seemed lost, a clearing appeared ahead. There, nestled among towering palms, stood another ancient ruin. This one bore intricate carvings depicting scenes of gods and mythical creatures. Could it be the resting place of the Elixir?\n",
            "\n",
            "Without pausing for breath, they rushed inside, their hearts pounding with anticipation. Inside, they found a chamber filled with golden idols and precious gemstones. At the center stood a pedestal upon which rested a small vial made of pure crystal. Its surface shimmered with an ethereal glow, reflecting the flickering torchlight.\n",
            "\n",
            "Steele's voice boomed through the entrance, sending tremors through the ground beneath their feet. \"Hand it over, Carter! I won't ask again!\"\n",
            "\n",
            "But even as danger lurked outside, Emma knew what she must do. With determination burning in her eyes, she stepped forward, holding out the vial towards the sky. \"This isn't about immortality, Steele. It's about legacy...about leaving something behind that lasts longer than us all.\"\n",
            "\n",
            "Her defiant stance took Steele aback, giving her teammates enough time to prepare a surprise counterattack. Suddenly, the room erupted in chaos as torches ignited the vast cache of explosives hidden within the walls.\n",
            "\n",
            "In the ensuing explosion, both sides were obliterated, leaving nothing but ash and rubble behind. Amidst the destruction, however, one thing remained untouched – the crystalline vial containing the Elixir of Immortality.\n",
            "\n",
            "And so, as dawn broke over the smoldering ruins, Emma, Raj, and Alex continued their journey, knowing that they had saved not only themselves but also the world from the clutches of a madman. For now, the secret of eternal life would remain hidden, waiting for those worthy enough to discover it.\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "As the sun rose higher in the sky, casting dappled light through the emerald leaves, our intrepid heroes found solace in the quietude of the forest. The adrenaline rush of their narrow escape still coursed through their veins, yet they knew they couldn't afford to rest on their laurels.\n",
            "\n",
            "First and foremost, they needed to ensure their safety. Emma suggested setting up camp further away from civilization, preferably near a water source. After hours of careful navigation, they stumbled upon a secluded spot beside a babbling brook. The lush greenery provided ample cover, making it an ideal location for their temporary shelter.\n",
            "\n",
            "While Raj busied himself with collecting firewood and preparing food, Emma and Alex discussed their next move. They agreed that returning to civilization wasn't an option; word of their encounter with Victor Steele would surely spread, putting them in grave danger. Instead, they decided to continue searching for the remaining pieces of the legendary Crystal Skull, rumored to hold the key to unlocking the true power of the Elixir.\n",
            "\n",
            "However, they soon realized that they lacked essential resources for such a prolonged expedition. They needed supplies, maps, and most importantly, information. To acquire these items, they planned to visit an old friend of Emma's – Dr. Marcus Thompson, a renowned anthropologist specializing in Mayan culture. His expertise might prove instrumental in helping them decipher cryptic texts related to the Crystal Skull.\n",
            "\n",
            "After bidding farewell to Raj, who chose to stay behind due to his vital role back at base, Emma and Alex embarked on their new quest. They traveled along winding rivers, scaled steep mountainsides, and braved treacherous jungle trails. Along the way, they encountered various obstacles, including wild animals, harsh weather conditions, and even hostile tribes. Yet, their resolve never wavered.\n",
            "\n",
            "One evening, as they huddled around a crackling campfire, they heard whispers of a legend passed down through generations. According to the tale, the final piece of the Crystal Skull was hidden deep within a sacred cave located high atop Mount Xibalba. This mountain was known for its volatile climate, characterized by frequent thunderstorms and lightning strikes.\n",
            "\n",
            "Despite the inherent risks involved, Emma saw an opportunity. If they managed to secure the Crystal Skull, they could potentially use its power to neutralize any potential threats against them. Armed with renewed vigor, they set off early the following morning, undeterred by the impending challenge.\n",
            "\n",
            "Days turned into weeks as they climbed the treacherous slopes of Mount Xibalba. Each step brought them closer to their goal, but each misstep threatened to send them plummeting to their demise. During their arduous climb, they faced numerous trials testing their courage, strength, and intellect.\n",
            "\n",
            "At one point, they encountered a particularly challenging puzzle involving a series of pressure plates embedded in the cavern wall. Solving it required precise timing and coordination. Failure meant triggering a deadly trapdoor leading to certain death. Drawing upon their combined skills, Emma and Alex worked tirelessly until finally, the hidden passageway opened up, revealing the inner sanctum of the cave.\n",
            "\n",
            "Breathless and exhilarated, they entered the dimly lit chamber. Before them lay the magnificent Crystal Skull, its facets gleaming in the faint glow emitted by luminescent fungi scattered throughout the room. Overwhelmed by emotion, they carefully lifted the priceless artifact, feeling its cool touch against their skin.\n",
            "\n",
            "Now armed with the complete Crystal Skull, they returned to their camp, eager to explore its secrets. However, little did they know, their greatest challenge yet awaited them. Unbeknownst to them, Victor Steele had survived the explosion and was hot on their trail.\n",
            "\n",
            "Determined to claim the Elixir for himself, Steele followed their every move, always staying just beyond reach. One night, as they settled down for the evening, they were ambushed by a large contingent of mercenaries sent by Steele. Outnumbered and outmatched, Emma and Alex fought valiantly, using every trick in their arsenal to keep their enemies at bay.\n",
            "\n",
            "Just when all hope seemed lost, a deafening roar echoed through the forest. From the darkness emerged Raj, having tracked their movements since their separation. Together, the trio launched a fierce counteroffensive, turning the tide of battle decisively in their favor. By dawn, the remnants of Steele's forces retreated, leaving our heroes victorious but battered and bruised.\n",
            "\n",
            "Having successfully thwarted Steele once more, they regrouped and devised a plan to safeguard the Elixir and the Crystal Skull. They decided to hide them in a remote location accessible only to select individuals sworn to protect them. Satisfied that their mission was accomplished, they bid farewell to each other, knowing that their lives would forever be intertwined in the annals of history.\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "As the sun began to rise over the horizon, painting the sky in hues of orange and pink, Emma, Alex, and Raj shared a moment of silence, acknowledging the gravity of their victory. Their hearts beat steadily, mirroring the rhythm of the forest around them. Despite the relief that washed over them, they understood that their journey was far from over.\n",
            "\n",
            "The Elixir of Immortality and the Crystal Skull were powerful relics, coveted by many for reasons both noble and nefarious. They held immense potential, capable of changing the course of human history if used correctly. But in the wrong hands, they could bring about devastation and chaos.\n",
            "\n",
            "To prevent such an outcome, they resolved to find trustworthy guardians for these priceless artifacts. They spent days poring over ancient manuscripts, consulting scholars, and traveling to distant lands, seeking answers. Eventually, they discovered an order of monks living deep within the Himalayas, famed for their wisdom and dedication to preserving historical knowledge.\n",
            "\n",
            "These monks, known as the Keepers of Time, welcomed the trio warmly, recognizing the significance of their quest. After rigorous tests designed to assess their character and intentions, they were granted access to the Sacred Caverns, a network of subterranean tunnels housing countless relics and artifacts. Here, amidst the serene atmosphere, they entrusted the Elixir and the Crystal Skull to the care of the Keepers.\n",
            "\n",
            "However, their work didn't end there. The trio knew that there would always be those who sought to exploit the power of the Elixir and the Crystal Skull for personal gain. To combat this threat, they dedicated themselves to spreading awareness about the importance of responsible stewardship and ethical use of ancient knowledge.\n",
            "\n",
            "Over the years, they traveled extensively, sharing their experiences and insights with scholars, historians, and spiritual leaders worldwide. Through lectures, publications, and collaborative research projects, they inspired a new generation of guardians committed to protecting humanity's collective heritage.\n",
            "\n",
            "Meanwhile, news of their accomplishments reached far and wide, earning them accolades and recognition. Institutions offered them positions of authority, allowing them to establish academic departments focused on archaeology, cultural preservation, and sustainable exploration practices.\n",
            "\n",
            "Yet, despite their achievements, they remained humble, always remembering the lessons learned during their perilous adventure. They continued to live simply, dedicating their lives to the pursuit of knowledge and the protection of history.\n",
            "\n",
            "Word of their exploits eventually reached Victor Steele, who, bitter and resentful, hatched a new scheme. Realizing that direct confrontations with the trio had yielded minimal results, he decided to manipulate events from behind the shadows. Using his extensive network of contacts, he began funding various criminal organizations, fueling conflict and instability across continents.\n",
            "\n",
            "His ultimate objective was to create chaos and disorder, hoping that in the resulting confusion, he could seize control of the Elixir and the Crystal Skull. But Emma, Alex, and Raj were well aware of his machinations. Working closely with international law enforcement agencies, they dismantled his operations one by one, exposing his criminal empire bit by bit.\n",
            "\n",
            "Each successive blow weakened Steele, forcing him to adapt and evolve his tactics. But the trio refused to let up, relentlessly pursuing him until he was cornered in a remote jungle stronghold. In a climactic showdown, they confronted him personally, bringing an end to his reign of terror.\n",
            "\n",
            "With Steele defeated, peace gradually restored itself to the world. People celebrated the return of stability and security, grateful for the efforts of the trio. News of their triumphant conclusion to the saga reached every corner of the globe, inspiring awe and admiration.\n",
            "\n",
            "Reflecting on their incredible journey, Emma, Alex, and Raj marveled at how far they had come. They had started as ordinary individuals driven by curiosity and passion, but they had transformed into respected guardians of history and champions of ethical exploration. Their bond had grown stronger with each passing day, transcending friendship and solidifying into an unbreakable alliance.\n",
            "\n",
            "As they gazed at the stars twinkling above, they knew that their story was far from finished. New challenges would arise, new mysteries would need solving, and new adventures would call out to them. But whatever lay ahead, they were ready, united by their common purpose and bound by their unwavering commitment to preserve the rich tapestry of human history.\n",
            "\n",
            "\n",
            "---\n",
            "\n",
            "As the sun began to dip below the horizon, casting elongated shadows across the jungle floor, the trio pressed onward, their spirits buoyed by the recent victory. Though Victor Steele had been vanquished, they knew that his defeat was merely a reprieve. The Elixir of Immortality and the Crystal Skull remained potent symbols of power, desired by many for nefarious purposes.\n",
            "\n",
            "Their journey home was fraught with challenges. They traversed treacherous terrains, battled ferocious wildlife, and navigated treacherous waters teeming with pirates and privateers. Yet, they remained resolute, drawing strength from their shared experiences and the knowledge that they were guardians of history.\n",
            "\n",
            "Upon their arrival at the Monastery of the Keepers of Time, they were greeted with open arms. The monks praised their valor and commended their selfless dedication to preserving the past for future generations. In gratitude, they bestowed upon Emma, Alex, and Raj the title of Honorary Guardians, granting them access to the monastery's vast library and archives.\n",
            "\n",
            "As they delved deeper into the troves of ancient knowledge, they discovered countless stories of civilizations long forgotten, tales of brave explorers who risked everything in pursuit of discovery, and accounts of legendary artifacts that shaped the course of history. Inspired by these narratives, they redoubled their efforts to promote ethical exploration practices and inspire a new generation of guardians.\n",
            "\n",
            "News of their exploits reached far and wide, capturing the imagination of people everywhere. Scholars, historians, and adventurers flocked to learn from them, drawn by their unique blend of experience, wisdom, and passion. They established educational programs aimed at fostering a love for history and encouraging young minds to seek knowledge and understanding.\n",
            "\n",
            "Throughout their travels, they encountered adversity in unexpected forms. Some criticized their methods, arguing that the pursuit of knowledge justified any means necessary. Others accused them of being gatekeepers, hoarding valuable information for themselves. But Emma, Alex, and Raj remained unfazed, refusing to compromise their principles.\n",
            "\n",
            "Instead, they embraced these challenges as opportunities to engage in thoughtful discourse and foster meaningful dialogue. They recognized that change was inevitable and that progress often demanded difficult choices. So, they adapted their approach, focusing on collaboration rather than competition, and emphasizing the importance of respecting diverse perspectives.\n",
            "\n",
            "As the years passed, they watched as their students grew into brilliant scholars and passionate advocates for historical preservation. They witnessed the establishment of institutions dedicated to promoting ethical exploration practices and supporting researchers in their endeavors. And they felt a sense of pride knowing that their influence extended beyond their immediate circle.\n",
            "\n",
            "But even as they reveled in their accomplishments, they knew that their work was far from done. New threats emerged, threatening the very fabric of history. False histories propagated lies and distorted truths, sowing seeds of division and strife. Myths and legends were twisted to serve political agendas, blurring the line between fact and fiction.\n",
            "\n",
            "Undaunted, they continued their mission, working tirelessly to debunk falsehoods and restore accuracy to historical records. They collaborated with experts from various fields, combining their respective areas of expertise to tackle complex issues. And they mentored the next generation of guardians, ensuring that their legacy lived on.\n",
            "\n",
            "Amidst the turmoil of a rapidly changing world, they remained steadfast in their convictions. They believed that the power of knowledge could bridge divides, heal wounds, and build bridges between communities. And they knew that their duty was to help others see the same potential.\n",
            "\n",
            "So, they traveled the world, sharing their insights and experiences, and inspiring others to join their cause. They spoke at conferences, published papers, and engaged in public debates, championing the importance of accurate historical record keeping and ethical exploration practices.\n",
            "\n",
            "Eventually, their names became synonymous with integrity, scholarship, and a deep appreciation for the value of history. They left an indelible mark on the world, inspiring generations to follow in their footsteps.\n",
            "\n",
            "But even as they aged, they never lost sight of their original goals. They continued to push boundaries, exploring new frontiers and expanding their horizons. And though they faced new challenges, they met them head-on, drawing inspiration from their past experiences and the knowledge that they were part of a larger narrative.\n",
            "\n",
            "As the sun set on their remarkable lives, they reflected on their journey, marveling at how far they had come. They had started as curious souls driven by a desire to understand the world around them. Now, they were revered guardians of history, champions of truth, and architects of a better tomorrow.\n",
            "\n",
            "And as they drifted off into the sweet embrace of sleep, they knew that their story was far from over. New chapters awaited them, filled with endless possibilities and exciting discoveries. And they looked forward to facing these challenges, confident in the knowledge that they were not alone.\n",
            "\n",
            "For they were part of a grand tradition, a proud legacy that stretched back millennia. They were custodians of the past, bearers of the torch passed down through generations. And they knew that their actions today would shape the future, guiding the next wave of explorers and scholars as they ventured forth into the unknown.\n",
            "\n",
            "So, they closed their eyes, content in the knowledge that their story was far from over. They dreamed of new adventures, of uncharted territories, and of untold stories waiting to be discovered. And they smiled, knowing that they would wake up tomorrow, ready to face another day filled with wonder and possibility.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeIsrOeFj1i0",
        "outputId": "464a7851-82e0-4276-adf8-e9d0526ec835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.0.1 (from gradio)\n",
            "  Downloading gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.4.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Collecting typer<1.0,>=0.12 (from gradio)\n",
            "  Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.0.1->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi->gradio)\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=486b98d47cf223b9d876d324e1ec35ab13fda28b2c68b39d07b85eb986200cd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, ujson, tomlkit, shellingham, semantic-version, ruff, python-multipart, python-dotenv, orjson, httptools, h11, dnspython, aiofiles, watchfiles, uvicorn, starlette, httpcore, email_validator, typer, httpx, gradio-client, fastapi-cli, fastapi, gradio\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.9.4\n",
            "    Uninstalling typer-0.9.4:\n",
            "      Successfully uninstalled typer-0.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "spacy 3.7.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\n",
            "weasel 0.3.4 requires typer<0.10.0,>=0.3.0, but you have typer 0.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.36.1 gradio-client-1.0.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 orjson-3.10.3 pydub-0.25.1 python-dotenv-1.0.1 python-multipart-0.0.9 ruff-0.4.8 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.37.2 tomlkit-0.12.0 typer-0.12.3 ujson-5.10.0 uvicorn-0.30.1 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(hero, villain, sidekick, victim, witness):\n",
        "    # Your story generation code here\n",
        "    pass\n",
        "\n",
        "hero_input = gr.Textbox(label=\"Hero\")\n",
        "villain_input = gr.Textbox(label=\"Villain\")\n",
        "sidekick_input = gr.Textbox(label=\"Sidekick\")\n",
        "victim_input = gr.Textbox(label=\"Victim\")\n",
        "witness_input = gr.Textbox(label=\"Witness\")\n",
        "\n",
        "output = gr.Textbox(label=\"Generated Story\")\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=generate_story,\n",
        "    inputs=[hero_input, villain_input, sidekick_input, victim_input, witness_input],\n",
        "    outputs=output,\n",
        "    title=\"Story Generator\",\n",
        "    description=\"Generate a complete story based on the Lester Dent Pulp Paper formula.\"\n",
        ")\n",
        "\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "rvViMZrvrlv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34L0_V_elm7z",
        "outputId": "95c3f7c5-5be8-4af2-c240-758aa6a1de97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.36.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==1.0.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.0.1)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.1.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLAONA1cmFFs",
        "outputId": "35b345bb-9297-45bc-f2e7-e27ff6ba8885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (3.50.0)\n",
            "Collecting gradio\n",
            "  Using cached gradio-4.36.1-py3-none-any.whl (12.3 MB)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Collecting gradio-client==1.0.1 (from gradio)\n",
            "  Using cached gradio_client-1.0.1-py3-none-any.whl (318 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.7.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.1)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.0.1->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.14.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.18.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (2.1.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio) (2.6.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (0.22.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Installing collected packages: gradio-client, gradio\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 0.6.1\n",
            "    Uninstalling gradio_client-0.6.1:\n",
            "      Successfully uninstalled gradio_client-0.6.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 3.50.0\n",
            "    Uninstalling gradio-3.50.0:\n",
            "      Successfully uninstalled gradio-3.50.0\n",
            "Successfully installed gradio-4.36.1 gradio-client-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio==3.50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09yecS2AoC5N",
        "outputId": "29be9ee1-c002-4b7a-95b8-e94af09eea41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio==3.50\n",
            "  Downloading gradio-3.50.0-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (0.111.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (0.3.2)\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (0.23.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (3.10.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (9.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (2.7.3)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (0.25.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (6.0.1)\n",
            "Requirement already satisfied: requests~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (2.31.0)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (4.12.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (0.30.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50) (11.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.6.1->gradio==3.50) (2023.6.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50) (0.12.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50) (3.14.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.0->gradio==3.50) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50) (4.53.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.50) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio==3.50) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.50) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.50) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.50) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests~=2.0->gradio==3.50) (2024.6.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.50) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.50) (0.14.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.50) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.50) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.50) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio==3.50) (2.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50) (1.3.1)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from email_validator>=2.0.0->fastapi->gradio==3.50) (2.6.1)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from fastapi-cli>=0.0.2->fastapi->gradio==3.50) (0.12.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (0.18.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.50) (1.2.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.50) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.50) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.50) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.50) (0.22.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.50) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.50) (13.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.50) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.50) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->gradio==3.50) (0.1.2)\n",
            "Installing collected packages: gradio-client, gradio\n",
            "  Attempting uninstall: gradio-client\n",
            "    Found existing installation: gradio_client 1.0.1\n",
            "    Uninstalling gradio_client-1.0.1:\n",
            "      Successfully uninstalled gradio_client-1.0.1\n",
            "  Attempting uninstall: gradio\n",
            "    Found existing installation: gradio 4.36.1\n",
            "    Uninstalling gradio-4.36.1:\n",
            "      Successfully uninstalled gradio-4.36.1\n",
            "Successfully installed gradio-3.50.0 gradio-client-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import gradio as gr\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "# Define the LLMs\n",
        "llm_first = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm_second = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm_third = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm_fourth = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# Define the prompt templates for each LLM\n",
        "template_first = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula is a writing guide created by Lester Dent, a prolific pulp fiction writer best known for his work on the \"Doc Savage\" series. Dent's formula provides a structured approach to crafting engaging and action-packed stories. Here is a brief overview of the formula:\n",
        "\n",
        "Introduction:\n",
        "Introduce the hero and the central problem or conflict.\n",
        "Set up a situation that hooks the reader's interest immediately.\n",
        "First Quarter:\n",
        "The hero tries to solve the problem.\n",
        "Introduce complications and obstacles that thwart the hero's initial attempts.\n",
        "Introduce other key characters (both allies and antagonists).\n",
        "End with a twist or a surprising development.\n",
        "\n",
        "Characters:\n",
        "- Hero: {hero}\n",
        "- Villain: {villain}\n",
        "- Sidekick: {sidekick}\n",
        "- Victim: {victim}\n",
        "- Witness: {witness}\n",
        "\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "Based on this formula, your task is to generate exactly the first 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "template_second = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Second Quarter:\n",
        "Escalate the conflict and introduce additional problems for the hero.\n",
        "The hero faces greater challenges and setbacks.\n",
        "Include physical conflicts or action scenes.\n",
        "Introduce a major plot twist or revelation that complicates the hero's mission.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "template_third = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Third Quarter:\n",
        "The hero makes some progress towards solving the problem but faces significant adversity.\n",
        "Introduce new conflicts and obstacles.\n",
        "The hero encounters the main villain or a critical turning point in the story.\n",
        "End with a twist that puts the hero in an even worse situation.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "This is the second part of the story:\n",
        "{second_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "template_fourth = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Final Quarter:\n",
        "The hero faces the greatest challenges and is pushed to their limits.\n",
        "All mysteries and plot threads are resolved.\n",
        "The hero uses their skills, intelligence, and bravery to overcome the final obstacles.\n",
        "End with a final twist or surprise that concludes the story in a satisfying way.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "This is the second part of the story:\n",
        "{second_part}\n",
        "\n",
        "This is the third part of the story:\n",
        "{third_part}\n",
        "\n",
        "Based on this formula, your task is to generate the final 1500 words of the story which is the last quarter of the story so you should end the story in this chapter,the generated text should be in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Fonctions de génération des parties de l'histoire\n",
        "def generate_story_part1(hero, villain, sidekick, victim, witness):\n",
        "    # Générer la première partie de l'histoire ici\n",
        "    story_part1 = \"Partie 1 générée par LLM1\"\n",
        "    return story_part1\n",
        "\n",
        "def generate_story_part2(story_part1_modified):\n",
        "    # Générer la deuxième partie de l'histoire ici en utilisant la partie modifiée de la première partie\n",
        "    story_part2 = \"Partie 2 générée par LLM2 en utilisant la partie modifiée de la première partie\"\n",
        "    return story_part2\n",
        "\n",
        "def generate_story_part3(story_part2_modified):\n",
        "    # Générer la troisième partie de l'histoire ici en utilisant la partie modifiée de la deuxième partie\n",
        "    story_part3 = \"Partie 3 générée par LLM3 en utilisant la partie modifiée de la deuxième partie\"\n",
        "    return story_part3\n",
        "\n",
        "def generate_story_part4(story_part3_modified):\n",
        "    # Générer la quatrième partie de l'histoire ici en utilisant la partie modifiée de la troisième partie\n",
        "    story_part4 = \"Partie 4 générée par LLM4 en utilisant la partie modifiée de la troisième partie\"\n",
        "    return story_part4\n",
        "\n",
        "# Fonctions de modification des parties de l'histoire\n",
        "def modify_story_part1(story_part1):\n",
        "    # Traiter la première partie de l'histoire modifiée ici\n",
        "    story_part1_modified = \"Partie 1 modifiée\"\n",
        "    return story_part1_modified\n",
        "\n",
        "def modify_story_part2(story_part2):\n",
        "    # Traiter la deuxième partie de l'histoire modifiée ici\n",
        "    story_part2_modified = \"Partie 2 modifiée\"\n",
        "    return story_part2_modified\n",
        "\n",
        "def modify_story_part3(story_part3):\n",
        "    # Traiter la troisième partie de l'histoire modifiée ici\n",
        "    story_part3_modified = \"Partie 3 modifiée\"\n",
        "    return story_part3_modified\n",
        "\n",
        "# Créer les entrées et sorties de l'interface Gradio\n",
        "hero_input = gr.Textbox(label=\"Hero\")\n",
        "villain_input = gr.Textbox(label=\"Villain\")\n",
        "sidekick_input = gr.Textbox(label=\"Sidekick\")\n",
        "victim_input = gr.Textbox(label=\"Victim\")\n",
        "witness_input = gr.Textbox(label=\"Witness\")\n",
        "\n",
        "story_part1_output = gr.Textbox(label=\"Partie 1 de l'histoire\")\n",
        "story_part1_modified_output = gr.Textbox(label=\"Partie 1 de l'histoire modifiée\")\n",
        "story_part2_output = gr.Textbox(label=\"Partie 2 de l'histoire\")\n",
        "story_part2_modified_output = gr.Textbox(label=\"Partie 2 de l'histoire modifiée\")\n",
        "story_part3_output = gr.Textbox(label=\"Partie 3 de l'histoire\")\n",
        "story_part3_modified_output = gr.Textbox(label=\"Partie 3 de l'histoire modifiée\")\n",
        "story_part4_output = gr.Textbox(label=\"Partie 4 de l'histoire\")\n",
        "\n",
        "# Créer l'interface Gradio\n",
        "interface = gr.Interface(\n",
        "    [generate_story_part1, generate_story_part2, generate_story_part3, generate_story_part4,\n",
        "     modify_story_part1, modify_story_part2, modify_story_part3],\n",
        "    [\n",
        "        hero_input, villain_input, sidekick_input, victim_input, witness_input,\n",
        "        story_part1_output, story_part1_modified_output, story_part2_output,\n",
        "        story_part2_modified_output, story_part3_output, story_part3_modified_output,\n",
        "        story_part4_output\n",
        "    ],\n",
        "    title=\"Story Generator\",\n",
        "    description=\"Generate a complete story based on the Lester Dent Pulp Paper formula.\",\n",
        "    allow_flagging=False\n",
        ")\n",
        "\n",
        "# Lancer l'interface Gradio\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "id": "Gwr1Oi5Xx4hq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "# Define the LLMs\n",
        "llm_first = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm_second = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm_third = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm_fourth = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# Define the prompt templates for each LLM\n",
        "template_first = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula is a writing guide created by Lester Dent, a prolific pulp fiction writer best known for his work on the \"Doc Savage\" series. Dent's formula provides a structured approach to crafting engaging and action-packed stories. Here is a brief overview of the formula:\n",
        "\n",
        "Introduction:\n",
        "Introduce the hero and the central problem or conflict.\n",
        "Set up a situation that hooks the reader's interest immediately.\n",
        "First Quarter:\n",
        "The hero tries to solve the problem.\n",
        "Introduce complications and obstacles that thwart the hero's initial attempts.\n",
        "Introduce other key characters (both allies and antagonists).\n",
        "End with a twist or a surprising development.\n",
        "\n",
        "Characters:\n",
        "- Hero: {hero}\n",
        "- Villain: {villain}\n",
        "- Sidekick: {sidekick}\n",
        "- Victim: {victim}\n",
        "- Witness: {witness}\n",
        "\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "Based on this formula, your task is to generate exactly the first 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "template_second = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Second Quarter:\n",
        "Escalate the conflict and introduce additional problems for the hero.\n",
        "The hero faces greater challenges and setbacks.\n",
        "Include physical conflicts or action scenes.\n",
        "Introduce a major plot twist or revelation that complicates the hero's mission.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "template_third = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Third Quarter:\n",
        "The hero makes some progress towards solving the problem but faces significant adversity.\n",
        "Introduce new conflicts and obstacles.\n",
        "The hero encounters the main villain or a critical turning point in the story.\n",
        "End with a twist that puts the hero in an even worse situation.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "This is the second part of the story:\n",
        "{second_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "template_fourth = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Final Quarter:\n",
        "The hero faces the greatest challenges and is pushed to their limits.\n",
        "All mysteries and plot threads are resolved.\n",
        "The hero uses their skills, intelligence, and bravery to overcome the final obstacles.\n",
        "End with a final twist or surprise that concludes the story in a satisfying way.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "This is the second part of the story:\n",
        "{second_part}\n",
        "\n",
        "This is the third part of the story:\n",
        "{third_part}\n",
        "\n",
        "Based on this formula, your task is to generate the final 1500 words of the story which is the last quarter of the story so you should end the story in this chapter,the generated text should be in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "# Function to combine all parts into one text\n",
        "import gradio as gr\n",
        "def combine_story_parts(*parts):\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "# Define the function to generate the story\n",
        "def generate_story(hero, villain, sidekick, victim, witness):\n",
        "    # Generate the first part\n",
        "    prompt_first = PromptTemplate.from_template(template_first)\n",
        "    first_result = llm_first(prompt_first.format(hero=hero, villain=villain, sidekick=sidekick, victim=victim, witness=witness))\n",
        "\n",
        "    # Generate the second part\n",
        "    prompt_second = PromptTemplate.from_template(template_second)\n",
        "    second_result = llm_second(prompt_second.format(first_part=first_result))\n",
        "\n",
        "    # Generate the third part\n",
        "    prompt_third = PromptTemplate.from_template(template_third)\n",
        "    third_result = llm_third(prompt_third.format(first_part=first_result, second_part=second_result))\n",
        "\n",
        "    # Generate the final part\n",
        "    prompt_fourth = PromptTemplate.from_template(template_fourth)\n",
        "    fourth_result = llm_fourth(prompt_fourth.format(first_part=first_result, second_part=second_result, third_part=third_result))\n",
        "\n",
        "    # Combine all parts\n",
        "    full_story = combine_story_parts(first_result, second_result, third_result, fourth_result)\n",
        "    return full_story\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "hero_input = gr.Textbox(label=\"Hero\")\n",
        "villain_input = gr.Textbox(label=\"Villain\")\n",
        "sidekick_input = gr.Textbox(label=\"Sidekick\")\n",
        "victim_input = gr.Textbox(label=\"Victim\")\n",
        "witness_input = gr.Textbox(label=\"Witness\")\n",
        "\n",
        "output = gr.Textbox(label=\"Generated Story\")\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=generate_story,\n",
        "    inputs=[hero_input, villain_input, sidekick_input, victim_input, witness_input],\n",
        "    outputs=output,\n",
        "    title=\"Story Generator\",\n",
        "    description=\"Generate a complete story based on the Lester Dent Pulp Paper formula.\"\n",
        ")\n",
        "\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "RkwNSseGjxBK",
        "outputId": "04a9117a-4177-4844-82b8-784d7215d92c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://91db15d7ef3917599a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://91db15d7ef3917599a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Characters:\n",
        "- Hero: Emma Carter, a fearless archaeologist with a knack for solving ancient mysteries.\n",
        "- Villain: Victor Steele, a ruthless treasure hunter obsessed with finding the legendary Elixir of Immortality.\n",
        "- Sidekick: Raj Patel, a tech-savvy historian assisting Emma.\n",
        "- Victim: Dr. Elena Gomez, a renowned historian murdered while researching the Elixir.\n",
        "- Witness: Alex Turner, a local guide who witnessed the crime."
      ],
      "metadata": {
        "id": "PKYGu61TqP7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIjDj9-9WcDL",
        "outputId": "e83be8b3-fa4f-40b7-e010-cf391a32913e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---\n",
            "\n",
            "In the heart of the Amazon rainforest, where sunlight barely penetrated the dense canopy, lay the crumbling ruins of an ancient civilization. A faint trail snaked through the undergrowth, leading to what was once a magnificent temple dedicated to the gods of water and fertility.\n",
            "\n",
            "Emma Carter, a seasoned archaeologist with sun-bleached hair and eyes as sharp as her machete, stood atop a weathered stone pedestal, surveying the overgrown structure. Her brow furrowed as she studied the glyphs etched into the temple walls - symbols long forgotten by time. She had been searching for years for clues about the elusive Elixir of Immortality, rumored to have been hidden deep within these jungles.\n",
            "\n",
            "Suddenly, a rustling sound echoed from nearby bushes. Startled, Emma spun around, her hand instinctively reaching for her sidearm. But it wasn't danger that emerged; instead, a young man stepped out, panting heavily. He wore tattered clothes and carried a backpack filled with supplies.\n",
            "\n",
            "\"Alex!\" Emma exclaimed, relief flooding her features. \"What are you doing here?\"\n",
            "\n",
            "Local guide Alex Turner looked sheepishly at her. \"I heard rumors of strange occurrences near this temple. I came to investigate.\"\n",
            "\n",
            "Emma sighed, shaking her head. \"This place isn't safe for amateurs, Alex. You could get yourself killed.\"\n",
            "\n",
            "He shrugged nonchalantly. \"Risk worth taking if there's a chance we might find something valuable.\"\n",
            "\n",
            "Just then, they heard gunshots ring out across the forest. Both froze, exchanging worried glances. They couldn't linger any longer. With determined strides, they followed the path back towards civilization, hoping to reach safety before whatever danger lurked ahead caught up with them.\n",
            "\n",
            "As they ventured deeper into the jungle, the sounds of chaos grew louder. Gunfire crackled through the air, punctuated by screams and shouts. Suddenly, a figure appeared before them - Victor Steele, a notorious treasure hunter infamous for his ruthlessness and cunning. His cold gaze fell upon Emma and Alex, narrowing as he recognized them.\n",
            "\n",
            "\"Well, well,\" he sneered, brandishing a wicked-looking pistol. \"If it isn't our dear friend, Dr. Carter, and her loyal sidekick. How unfortunate that I must interrupt your little adventure.\"\n",
            "\n",
            "Before either could react, several armed mercenaries burst onto the scene, surrounding them. Emma gritted her teeth, readying herself for battle. She knew they wouldn't stand a chance against such overwhelming odds unless they acted fast.\n",
            "\n",
            "With lightning reflexes, she lunged forward, slicing through the air with her machete. Caught off guard, the mercenaries stumbled, giving Emma and Alex an opening. Together, they fought fiercely, dodging bullets and counterattacking with all their strength.\n",
            "\n",
            "But despite their valiant efforts, they were vastly outnumbered. Just when hope seemed lost, a roar split the air, followed by the thunderous charge of a herd of enraged jaguars. Chaos erupted as men screamed and fled, leaving Emma and Alex standing victoriously amidst the carnage.\n",
            "\n",
            "Breathless and battered, they watched as Victor stealthily retreated, disappearing into the foliage. Frustrated but alive, they regrouped, knowing that this was far from over. Their quest for the Elixir would continue, no matter what dangers awaited them.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "Firstllm = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "\n",
        "template = \"\"\"The Lester Dent Pulp Paper Master Fiction Plot Formula is a writing guide created by Lester Dent, a prolific pulp fiction writer best known for his work on the \"Doc Savage\" series. Dent's formula provides a structured approach to crafting engaging and action-packed stories. Here is a brief overview of the formula:\n",
        "\n",
        "Introduction:\n",
        "\n",
        "Introduce the hero and the central problem or conflict.\n",
        "Set up a situation that hooks the reader's interest immediately.\n",
        "First Quarter:\n",
        "\n",
        "The hero tries to solve the problem.\n",
        "Introduce complications and obstacles that thwart the hero's initial attempts.\n",
        "Introduce other key characters (both allies and antagonists).\n",
        "End with a twist or a surprising development.\n",
        "Second Quarter:\n",
        "\n",
        "Escalate the conflict and introduce additional problems for the hero.\n",
        "The hero faces greater challenges and setbacks.\n",
        "Include physical conflicts or action scenes.\n",
        "Introduce a major plot twist or revelation that complicates the hero's mission.\n",
        "Third Quarter:\n",
        "\n",
        "The hero makes some progress towards solving the problem but faces significant adversity.\n",
        "Introduce new conflicts and obstacles.\n",
        "The hero encounters the main villain or a critical turning point in the story.\n",
        "End with a twist that puts the hero in an even worse situation.\n",
        "Final Quarter:\n",
        "\n",
        "The hero faces the greatest challenges and is pushed to their limits.\n",
        "All mysteries and plot threads are resolved.\n",
        "The hero uses their skills, intelligence, and bravery to overcome the final obstacles.\n",
        "End with a final twist or surprise that concludes the story in a satisfying way.\n",
        " this is the first and the second and the third part of the story ;\n",
        "Characters:\n",
        "- Hero: Emma Carter, a fearless archaeologist with a knack for solving ancient mysteries.\n",
        "- Villain: Victor Steele, a ruthless treasure hunter obsessed with finding the legendary Elixir of Immortality.\n",
        "- Sidekick: Raj Patel, a tech-savvy historian assisting Emma.\n",
        "- Victim: Dr. Elena Gomez, a renowned historian murdered while researching the Elixir.\n",
        "- Witness: Alex Turner, a local guide who witnessed the crime.\n",
        "\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "Based on this formula, your task is to generate exactly the first 1500 words of the story in one continuous block of text.which mean generate the first chapter of the story ; The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# Generate the initial story outline\n",
        "initial_result = Firstllm(prompt.format())\n",
        "print(initial_result)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQyb4iddbdpr",
        "outputId": "3e58fd7b-e99b-46a1-c8d9-4f76cf215b47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---\n",
            "\n",
            "As the adrenaline subsided, Emma and Alex took stock of their surroundings. The jungle had fallen silent again, save for the distant calls of howler monkeys. Exhaustion crept over them, yet they knew they couldn't afford to rest just yet. There was still the matter of finding the Elixir and dealing with Victor Steele.\n",
            "\n",
            "They pressed onward, following the trail deeper into the jungle. As they journeyed further, the terrain became more treacherous, with vines tangling around trees and rocks concealed beneath layers of leaves. It felt as though nature itself was trying to thwart their progress.\n",
            "\n",
            "Despite the difficulties, they persevered, driven by their determination to uncover the secrets of the ancient civilization. Along the way, they encountered various challenges – crossing swift-flowing rivers teeming with piranhas, navigating labyrinthine caverns filled with deadly traps, and deciphering cryptic riddles carved into stone tablets. Each hurdle only served to strengthen their resolve.\n",
            "\n",
            "Meanwhile, news of their discovery spread among rival treasure hunters. More groups began appearing in the area, each led by ambitious individuals eager to claim the Elixir for themselves. This escalated the conflict significantly, forcing Emma and Alex to confront numerous enemies along their path.\n",
            "\n",
            "One night, while setting up camp beside a crystal-clear lake, they were ambushed by a group of raiders. Armed with spears and bows, they closed in quickly, catching Emma and Alex off guard. In desperation, Emma grabbed her trusty machete and charged at the attackers, hacking and slashing wildly. Alex, too, joined the fray, using his agility to evade blows and strike back with precision.\n",
            "\n",
            "After a grueling fight, they managed to subdue their assailants. However, during the struggle, they noticed a peculiar symbol etched onto one raider's chest – the same symbol found throughout the temple complex. Realizing its significance, they deduced that these raiders belonged to Victor Steele's organization.\n",
            "\n",
            "Determined to put an end to this, they decided to track down Victor himself. Following another lead, they arrived at an abandoned gold mine, known to be one of Steele's hideouts. Upon entering, they discovered a massive underground chamber filled with priceless artifacts and relics stolen from various excavations sites. At the center stood a large pedestal, upon which rested a golden chalice.\n",
            "\n",
            "Steele appeared suddenly, flanked by a squad of heavily-armed guards. Smirking, he addressed them coolly. \"Ah, Dr. Carter and Mr. Turner. I see you've made quite the impression on my colleagues. Too bad they won't be joining us anymore.\"\n",
            "\n",
            "Ignoring his taunts, Emma and Alex prepared for a final showdown. The ensuing battle was fierce and intense, with both sides trading powerful blows. Despite being outnumbered, they held their ground, fueled by their desire to protect the precious knowledge contained within the Elixir.\n",
            "\n",
            "During the height of the battle, however, a sudden earthquake shook the mine, causing parts of the ceiling to collapse. Amidst the chaos, Emma spotted an opportunity and seized it, sealing off the entrance behind them, trapping Steele and his men inside.\n",
            "\n",
            "Exhilarated but drained, they escaped the collapsing mine, leaving Victor and his crew to face certain doom. Though they had triumphed, they knew their victory was far from complete. The Elixir remained elusive, and they needed rest and supplies before continuing their search.\n",
            "\n",
            "Resting at a remote campsite, they shared stories of past adventures and close calls. For the first time since embarking on this dangerous quest, they allowed themselves to relax, feeling grateful for having survived thus far. Yet, they also understood that the road ahead would be fraught with even greater challenges.\n",
            "\n",
            "And so, as dawn broke over the jungle, they packed their belongings and resumed their journey, ready to face whatever trials awaited them in pursuit of the legendary Elixir of Immortality.\n"
          ]
        }
      ],
      "source": [
        "llm_second = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# Define the prompt template for the second LLM\n",
        "template_second = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Second Quarter:\n",
        "Escalate the conflict and introduce additional problems for the hero.\n",
        "The hero faces greater challenges and setbacks.\n",
        "Include physical conflicts or action scenes.\n",
        "Introduce a major plot twist or revelation that complicates the hero's mission.\n",
        "Third Quarter:\n",
        "The hero makes some progress towards solving the problem but faces significant adversity.\n",
        "Introduce new conflicts and obstacles.\n",
        "The hero encounters the main villain or a critical turning point in the story.\n",
        "End with a twist that puts the hero in an even worse situation.\n",
        "Final Quarter:\n",
        "The hero faces the greatest challenges and is pushed to their limits.\n",
        "All mysteries and plot threads are resolved.\n",
        "The hero uses their skills, intelligence, and bravery to overcome the final obstacles.\n",
        "End with a final twist or surprise that concludes the story in a satisfying way.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story,which mean the Second Quarter ,in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "prompt_second = PromptTemplate.from_template(template_second)\n",
        "\n",
        "# Generate the continuation of the story\n",
        "second_result = llm_second(prompt_second.format(first_part=initial_result))\n",
        "print(second_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7FacG9JbUG1"
      },
      "outputs": [],
      "source": [
        "llm_second = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "# Define the prompt template for the second LLM\n",
        "template_second = \"\"\"\n",
        "The Lester Dent Pulp Paper Master Fiction Plot Formula continues as follows:\n",
        "\n",
        "Second Quarter:\n",
        "Escalate the conflict and introduce additional problems for the hero.\n",
        "The hero faces greater challenges and setbacks.\n",
        "Include physical conflicts or action scenes.\n",
        "Introduce a major plot twist or revelation that complicates the hero's mission.\n",
        "Third Quarter:\n",
        "The hero makes some progress towards solving the problem but faces significant adversity.\n",
        "Introduce new conflicts and obstacles.\n",
        "The hero encounters the main villain or a critical turning point in the story.\n",
        "End with a twist that puts the hero in an even worse situation.\n",
        "Final Quarter:\n",
        "The hero faces the greatest challenges and is pushed to their limits.\n",
        "All mysteries and plot threads are resolved.\n",
        "The hero uses their skills, intelligence, and bravery to overcome the final obstacles.\n",
        "End with a final twist or surprise that concludes the story in a satisfying way.\n",
        "\n",
        "This is the first part of the story:\n",
        "{first_part}\n",
        "\n",
        "Based on this formula, your task is to generate the next 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "prompt_second = PromptTemplate.from_template(template_second)\n",
        "\n",
        "# Generate the continuation of the story\n",
        "second_result = llm_second(prompt_second.format(first_part=initial_result))\n",
        "print(second_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl5WorLmdl6I",
        "outputId": "c0951acb-c115-4f46-dd3f-cb9ef4b3a7e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "As the sun began to dip below the horizon, painting the sky in hues of orange and pink, the trio of adventurers found themselves standing atop a desolate hill overlooking the sprawling cityscape of San Francisco. The weight of their mission pressed heavily upon their shoulders, fueling their determination to succeed.\n",
            "\n",
            "Emma, her sun-streaked hair blowing wildly in the cool breeze, scanned the urban expanse below. \"There,\" she announced, pointing towards a gleaming tower rising majestically amidst the concrete jungle. \"That's where we'll find him.\"\n",
            "\n",
            "Victor Steele, the infamous treasure hunter, had evaded capture for months, always managing to stay one step ahead of the law. But now, with the Elixir in their possession, the stakes were higher than ever. They needed to apprehend him before he could cause irreparable damage.\n",
            "\n",
            "Raj, his eyes focused intently on the map laid out before them, nodded in agreement. \"We've tracked him to the headquarters of his latest business venture – the Genesis Corporation. Rumor has it that he's using advanced technology to create counterfeit versions of priceless historical artifacts.\"\n",
            "\n",
            "Dr. Gomez, her brow furrowed in concentration, added, \"And with the Elixir, who knows what other nefarious schemes he might be planning?\"\n",
            "\n",
            "As they descended the hillside, their steps echoed ominously against the quiet night. The streets were deserted, save for the occasional late-night worker hurrying home. The silence was broken only by the distant hum of traffic and the occasional barking dog.\n",
            "\n",
            "Reaching the Genesis Corporation building, they found it well-guarded. Armed guards patrolled the perimeter, their watchful eyes missing nothing. Stealthily, they slipped into the shadows, observing the comings and goings of the facility.\n",
            "\n",
            "After hours of careful surveillance, they spotted Steele entering a hidden laboratory deep within the complex. Accompanying him was a familiar face – Dr. Jameson, a former colleague of Dr. Gomez. Disgusted by the direction her research had taken, she had distanced herself from the academic world. Now, unwittingly drawn back into the fold, she found herself trapped in a web of deceit and corruption.\n",
            "\n",
            "Making a quick decision, the trio devised a plan to infiltrate the lab and confront Steele. Utilizing their combined skills, they managed to disable the security systems and gain entry. Inside, they found Dr. Jameson bound and gagged, her pleading eyes meeting their sympathetic gazes.\n",
            "\n",
            "\"Thank goodness you're here,\" she breathed, tears streaming down her cheeks. \"I didn't want to be a part of this anymore. Please, you have to stop him.\"\n",
            "\n",
            "Emma nodded gravely, her resolve strengthened by the sight of her friend's distress. \"Lead us to him,\" she commanded, her voice steady and firm.\n",
            "\n",
            "Following Dr. Jameson's lead, they entered a dimly lit chamber where Steele stood before a large vat filled with bubbling green liquid. The Elixir, in its raw state, appeared menacing and volatile.\n",
            "\n",
            "\"Ah, my dear friends,\" Steele sneered, his smirk betraying no hint of fear. \"So nice of you to join me. I've been expecting you.\"\n",
            "\n",
            "Ignoring his taunts, Emma charged forward, her whip cracking through the air. Steele dodged nimbly, parrying her attacks with ease. Despite his age, he proved to be a formidable opponent, matching her skill blow for blow.\n",
            "\n",
            "Meanwhile, Raj and Dr. Gomez worked tirelessly to sabotage the machinery surrounding the Elixir vat. Sparks flew as circuits shorts and motors malfunctioned, threatening to ignite the volatile substance.\n",
            "\n",
            "Back and forth, the battle raged on. Emma's determination was matched only by Steele's cunning and resourcefulness. Just when it seemed that all hope was lost, Dr. Gomez managed to trigger a chain reaction, causing the entire lab to collapse inward.\n",
            "\n",
            "With a desperate cry, Steele leaped onto a precariously balanced platform, narrowly escaping the crashing debris. Grasping the Elixir vial tightly in one hand, he vanished into the chaos, disappearing from sight.\n",
            "\n",
            "Defeated but not deterred, the trio regrouped, their minds racing with thoughts of how to prevent the Elixir from falling into the wrong hands once more.\n",
            "\n",
            "\"We must alert the authorities and destroy any remaining traces of the Elixir,\" Emma decreed. \"No one deserves the power it grants.\"\n",
            "\n",
            "Working together, they managed to contain the situation, ensuring that the Elixir would remain a closely guarded secret. News of their victory spread rapidly, earning them accolades and admiration from their peers.\n",
            "\n",
            "But even as they basked in their triumph, they knew that their work was far from over. New threats loomed on the horizon, demanding their attention and resolve. United by their common goal, they vowed to stand strong against the tide of darkness, safeguarding the future of humanity.\n",
            "\n",
            "And so, the three brave souls continued their adventures, their bond of friendship and loyalty unbreakable. Through trials and tribulations, they faced the unknown, proving that sometimes, the greatest victories are born from the smallest seeds of courage and determination.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "\n",
        "template = \"\"\"The Lester Dent Pulp Paper Master Fiction Plot Formula is a writing guide created by Lester Dent, a prolific pulp fiction writer best known for his work on the \"Doc Savage\" series. Dent's formula provides a structured approach to crafting engaging and action-packed stories. Here is a brief overview of the formula:\n",
        "\n",
        "Introduction:\n",
        "\n",
        "Introduce the hero and the central problem or conflict.\n",
        "Set up a situation that hooks the reader's interest immediately.\n",
        "First Quarter:\n",
        "\n",
        "The hero tries to solve the problem.\n",
        "Introduce complications and obstacles that thwart the hero's initial attempts.\n",
        "Introduce other key characters (both allies and antagonists).\n",
        "End with a twist or a surprising development.\n",
        "Second Quarter:\n",
        "\n",
        "Escalate the conflict and introduce additional problems for the hero.\n",
        "The hero faces greater challenges and setbacks.\n",
        "Include physical conflicts or action scenes.\n",
        "Introduce a major plot twist or revelation that complicates the hero's mission.\n",
        "Third Quarter:\n",
        "\n",
        "The hero makes some progress towards solving the problem but faces significant adversity.\n",
        "Introduce new conflicts and obstacles.\n",
        "The hero encounters the main villain or a critical turning point in the story.\n",
        "End with a twist that puts the hero in an even worse situation.\n",
        "Final Quarter:\n",
        "\n",
        "The hero faces the greatest challenges and is pushed to their limits.\n",
        "All mysteries and plot threads are resolved.\n",
        "The hero uses their skills, intelligence, and bravery to overcome the final obstacles.\n",
        "End with a final twist or surprise that concludes the story in a satisfying way.\n",
        " this is the first and the second and the third part of the story ;\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Emma Carter, a seasoned archaeologist with sun-streaked hair and eyes as sharp as her trowels, stood before the crumbling ruins of the ancient Mayan temple. Her heart pounded with excitement as she traced the intricate glyphs etched into its weathered walls. This was no ordinary dig site; it held the promise of uncovering the long-lost secret of the Elixir of Immortality.\n",
        "\n",
        "A sudden rustling in the undergrowth jolted her from her reverie. She spun around, her hand instinctively reaching for the worn leather holster at her side where her.38 revolver lay hidden. A figure emerged from the shadows - tall, lean, and menacingly clad in black. It was Victor Steele, notorious treasure hunter and Emma's most formidable rival. His cold, calculating gaze bore into hers, chilling her to the bone.\n",
        "\n",
        "\"Carter,\" he sneered, \"I knew you wouldn't let me down again.\" He brandished a wicked-looking machete, its blade glinting dangerously in the dappled sunlight filtering through the dense foliage above them.\n",
        "\n",
        "Before she could react, a shrill cry pierced the air. From behind them came running Raj Patel, her loyal sidekick and confidant. In his hands, he carried a satellite phone. \"Professor! We have a problem!\"\n",
        "\n",
        "Raj's urgent voice brought Emma back to reality. She quickly assessed the situation. They were outnumbered and vastly outmatched. But they couldn't abandon their quest. Not when they were so close to discovering the truth about the Elixir.\n",
        "\n",
        "As if on cue, another shadowy figure stepped forward. This time it was Dr. Elena Gomez, a brilliant historian and colleague whose expertise had been instrumental in deciphering many of the cryptic symbols adorning the temple walls. Her terrified expression spoke volumes. She had stumbled upon something terrible - something that threatened not only their lives but also the very existence of humanity itself.\n",
        "\n",
        "Together, the trio retreated deeper into the jungle, pursued relentlessly by Steele and his henchmen. As they ran, they exchanged frantic whispers about what they had discovered: the Elixir wasn't just a myth or a legend; it was real, and in the wrong hands, it would bring untold destruction.\n",
        "\n",
        "They reached the safety of a nearby village just as dawn broke over the horizon. Exhausted yet determined, they sought refuge among the friendly locals. But little did they know that their respite would be short-lived. For word had spread of their discovery, and soon enough, both friends and foes alike converged upon them, each driven by their own desires and motivations.\n",
        "\n",
        "Among these arrivals was Alex Turner, a local guide who claimed to have seen Dr. Gomez being attacked near the temple earlier that morning. With him arrived a team of federal agents led by Agent Thompson, eager to secure the Elixir for the good of mankind. And then there was Victor Steele, ever persistent, intent on claiming the prize for himself.\n",
        "\n",
        "In the midst of this chaos, Emma found herself torn between protecting the Elixir from falling into the wrong hands and ensuring the safety of those closest to her. As the day wore on, alliances shifted, loyalties wavered, and secrets were revealed. Amidst it all, one thing remained clear: whoever possessed the Elixir would hold the power to change the course of history forever.\n",
        "\n",
        "With nightfall approaching, Emma made a decision. She would risk everything to keep the Elixir safe. Together with Raj and Dr. Gomez, they devised a plan to safeguard the precious artifact until they could find a way to harness its power responsibly.\n",
        "\n",
        "But even as they put their plan into motion, they knew that victory was far from guaranteed. For Victor Steele was a formidable opponent, and he would stop at nothing to claim the Elixir for himself. And lurking in the background were forces beyond their understanding, entities bound by the same primal desire for immortality that drove Steele.\n",
        "\n",
        "As the moon rose high overhead, casting eerie shadows across the jungle floor, Emma steeled herself for the battles ahead. Little did she know that the true test of courage, determination, and friendship was yet to come.\n",
        "As the darkness deepened, the once vibrant jungle seemed to transform into a sinister labyrinth of shadows and whispers. The sounds of the forest grew more ominous, punctuated by the occasional distant roar of howler monkeys warning of impending danger.\n",
        "\n",
        "Emma, Raj, and Dr. Gomez huddled together in the dimly lit recesses of a small cave nestled within the base of a colossal banyan tree. Their hearts beat in syncopated rhythm against their chests, echoing the palpable tension that hung heavy in the air.\n",
        "\n",
        "\"We must act fast,\" Dr. Gomez urged, her voice barely audible above the din of the jungle. \"Steele will surely return with reinforcements soon.\"\n",
        "\n",
        "Emma nodded grimly, her mind racing with possible solutions. \"Alex may still be able to help us,\" she suggested. \"He knows the terrain better than anyone else. Perhaps we can use that to our advantage.\"\n",
        "\n",
        "Just then, a faint crackle of static emanated from Raj's satphone. He listened intently, his brow furrowing as he absorbed the information transmitted through the tiny speaker. When he finally looked up, his face bore a mixture of relief and concern.\n",
        "\n",
        "\"Agent Thompson has secured the perimeter,\" he reported. \"His team is searching for us now, but they haven't located us yet.\"\n",
        "\n",
        "Dr. Gomez sighed heavily. \"That buys us some time, but it won't last long. We need to move quickly.\"\n",
        "\n",
        "Emma agreed. \"Let's split up. I'll take care of Steele and his men. You two focus on securing the Elixir and getting it to a place where it can be studied safely.\"\n",
        "\n",
        "As they prepared to separate, a low growl resonated through the trees. Startled, they turned to see a massive jaguar emerging from the shadows, its amber eyes fixed on them with predatory intensity.\n",
        "\n",
        "\"Quickly!\" Emma whispered urgently, pushing Dr. Gomez and Raj toward the exit. \"Go! I'll handle this.\"\n",
        "\n",
        "With a fierce determination burning in her veins, Emma faced off against the powerful predator. Using every ounce of strength and agility honed through years of adventure and exploration, she managed to subdue the beast, leaving it momentarily stunned. Seizing the opportunity, she grabbed the creature's tail and dragged it away from the entrance, buying her companions valuable time.\n",
        "\n",
        "Meanwhile, Raj and Dr. Gomez sprinted through the jungle, their footsteps accompanied by the sound of pursuit growing louder and closer behind them. They could hear Steele's cruel laughter ringing through the trees, taunting them mercilessly.\n",
        "\n",
        "Desperate for a means of escape, they stumbled upon an old Mayan burial ground hidden deep within the forest. Its entrance was marked by a towering stone statue depicting a serene deity holding a crystal orb – a symbol of eternal life.\n",
        "\n",
        "Realizing that this might be their only chance, they hurried inside, closing the door behind them just as a volley of gunshots rang out outside. The chamber was filled with countless relics and treasures, remnants of a civilization long gone. Among them, however, was the Elixir, resting peacefully in a golden urn.\n",
        "\n",
        "Breathing a sigh of relief, Dr. Gomez carefully lifted the urn, cradling it gently in her arms. \"Now we just need to get this to a laboratory for analysis,\" she said, her voice trembling slightly with exhaustion and fear.\n",
        "\n",
        "Suddenly, the ground beneath their feet began to shake violently. The walls of the tomb started to crumble, revealing a hidden passage leading deeper into the earth. An unearthly glow emanated from within, illuminating the room with an ethereal light.\n",
        "\n",
        "From the depths of the passage emerged figures unlike anything they had encountered before. These beings radiated an otherworldly energy, their forms shifting and shimmering with each passing moment. They moved gracefully, almost dancing in harmony with the pulsating rhythm of the earth itself.\n",
        "\n",
        "Recognizing the threat these creatures posed, Dr. Gomez acted swiftly. She opened the urn, releasing the Elixir into the chamber. Instantly, the beings paused, their gazes fixated on the golden liquid. Then, as if responding to a silent command, they bowed their heads, their bodies dissolving into wisps of smoke that drifted harmlessly upward.\n",
        "\n",
        "Overwhelmed by the turn of events, Raj and Dr. Gomez stared at each other in disbelief. \"What just happened?\" Raj asked, his voice barely audible above the rumble of collapsing rock and debris outside.\n",
        "\n",
        "Dr. Gomez hesitated, her eyes wide with wonder and fear. \"These beings...they worshipped the Elixir as a god,\" she explained. \"It seems that its power extends beyond mere mortality. It holds the ability to appease even the oldest and most primal desires.\"\n",
        "\n",
        "As the dust settled and the last vestiges of danger faded away, Emma emerged from the shadows, battered but triumphant. She joined her companions, her relief evident as she took in their safe arrival.\n",
        "\n",
        "Together, they left the tomb, carrying with them not only the knowledge of the Elixir's divine properties but also a renewed sense of purpose. They vowed to dedicate themselves to studying the elixir further, hoping to unlock its potential for the benefit of mankind rather than succumbing to its temptations.\n",
        "\n",
        "And thus, the journey continued, the trio venturing forth into the unknown, guided by curiosity, courage, and the belief that the power of the Elixir could indeed change the course of history for the better.\n",
        "As the sun began to rise over the dense jungles of Central America, the trio of adventurers found themselves huddled together in the dimly lit recesses of a hidden cave. The previous day had been fraught with danger and uncertainty, testing their resolve and determination to protect the Elixir of Immortality from falling into the wrong hands.\n",
        "\n",
        "Exhaling deeply, Emma surveyed her companions with a mix of pride and concern. Raj, his dark eyes reflective of the flickering torchlight, busied himself with checking their supplies. Dr. Gomez, her fair complexion contrasting starkly against the rough-hewn walls of the cavern, pored over ancient manuscripts, seeking answers to the enigmatic powers contained within the Elixir.\n",
        "\n",
        "\"We cannot rest here for long,\" Dr. Gomez warned, her voice barely audible above the gentle trickle of water droplets seeping through the cave ceiling. \"Victor Steele and his men will undoubtedly continue their search for the Elixir. We must find a safer location to study its properties.\"\n",
        "\n",
        "Nodding in agreement, Emma considered their options. \"Perhaps we could seek assistance from the local authorities,\" she suggested. \"Surely, they would understand the importance of keeping such a powerful substance out of the wrong hands.\"\n",
        "\n",
        "However, her optimism was met with skepticism from her colleagues. \"The authorities are likely already compromised,\" Raj pointed out. \"Steele has extensive connections and influence. If he wants something, he usually gets it.\"\n",
        "\n",
        "Dr. Gomez concurred. \"Our best bet is to leave this place and go into hiding. Somewhere remote, where we can conduct our research without interference.\"\n",
        "\n",
        "Emma nodded thoughtfully. \"Then we must act quickly. Before Steele catches wind of our movements.\"\n",
        "\n",
        "She glanced around the cave, taking note of the various relics scattered throughout the chamber. One particular item caught her eye – a beautifully crafted gold amulet bearing the image of a serpent entwined around a staff. According to legend, this artifact was believed to possess the power to communicate with the spirits of the land.\n",
        "\n",
        "\"This could be our ticket out of here,\" she mused aloud. \"If we can locate the priest or guardian associated with this talisman, perhaps they can offer us sanctuary.\"\n",
        "\n",
        "Her companions shared a look of mutual understanding. Together, they embarked on a new leg of their journey, following the trail of the mysterious amulet deep into the heart of the jungle.\n",
        "\n",
        "Days passed as they traversed the rugged terrain, encountering numerous challenges along the way. They braved treacherous river crossings, navigated through tangled webs of thorny vines, and endured torrential rainstorms that tested their resolve. Yet, despite these hardships, their spirit remained unbroken.\n",
        "\n",
        "At length, they arrived at a secluded valley nestled amidst rolling hills and verdant forests. Here, they found a quaint village inhabited by a peaceful tribe known as the Xibalba people. Their name derived from the ancient Mayan term meaning 'place of fear,' a reference to the trials and tribulations they had endured during their ancestors' struggle for survival.\n",
        "\n",
        "Warm smiles greeted the travelers as they approached the village square, where a bustling market teemed with activity. Children played joyfully amongst the colorful stalls selling exotic fruits, fragrant spices, and intricately designed pottery. Elderly women gossiped animatedly beside large clay ovens, while young men practiced archery and spear throwing techniques.\n",
        "\n",
        "Approaching the village elder, a wise and venerable woman named Tzitzimitl, they presented her with the gold amulet as proof of their connection to the sacred land. Impressed by their tenacity and respect for tradition, she welcomed them warmly into her community.\n",
        "\n",
        "Under her guidance, they were granted access to a hidden underground chamber containing a wealth of knowledge and wisdom. Here, they spent weeks poring over ancient texts and scrolls, learning about the origins of the Elixir and its profound impact on human history.\n",
        "\n",
        "One evening, as they gathered around a crackling campfire, Dr. Gomez shared her latest findings. \"According to these records, the Elixir was originally intended to grant its consumer the gift of eternal youth and vitality,\" she explained. \"But over time, its power became corrupted, leading to greed, ambition, and ultimately, destruction.\"\n",
        "\n",
        "Her words struck a somber tone amongst the group. \"We cannot allow such devastating consequences to befall mankind once more,\" Emma declared firmly. \"We must ensure that the Elixir is used responsibly and for the greater good.\"\n",
        "\n",
        "Determined to fulfill their duty, the trio dedicated themselves wholeheartedly to their research. They experimented with various combinations of ingredients, drawing inspiration from the abundant resources provided by the generous Xibalba people. Slowly but steadily, they began to unravel the secrets locked within the Elixir.\n",
        "\n",
        "Months went by, and the once vibrant colors of autumn leaves painted the landscape around them. The days grew shorter, and the nights longer, signifying the approach of winter. Finally, after much trial and error, they achieved their goal.\n",
        "\n",
        "Holding the newly formed Elixir in delicate glass vials, they marveled at the radiant golden liquid that shimmered softly in the firelight. \"We have done it,\" Raj exclaimed, his voice filled with awe and accomplishment.\n",
        "\n",
        "Emma smiled proudly at her companions. \"Now, we must ensure that this knowledge remains protected and does not fall into the wrong hands.\"\n",
        "\n",
        "Together, they decided to divide the Elixir amongst trusted individuals and organizations worldwide. Each recipient pledged to use the Elixir solely for scientific advancement and medical breakthroughs, thereby preventing its misuse and preserving the balance of nature.\n",
        "\n",
        "As they bid farewell to the Xibalba people, their hearts swelled with gratitude and appreciation for the opportunities afforded to them. They returned home, knowing that they had fulfilled their mission and safeguarded the future of humanity.\n",
        "\n",
        "Yet, even as they celebrated their success, they understood that their work was never truly complete. New threats and challenges awaited them, requiring constant vigilance and adaptability. But armed with the knowledge and experience gained during their incredible journey, they faced the future with confidence and hope.\n",
        "\n",
        "For in the end, it was not the Elixir of Immortality that granted them eternal life, but rather their indomitable spirit, unwavering commitment, and the bonds of camaraderie forged amidst the trials and tribulations of their extraordinary adventure.\n",
        "Characters:\n",
        "- Hero: Emma Carter, a fearless archaeologist with a knack for solving ancient mysteries.\n",
        "- Villain: Victor Steele, a ruthless treasure hunter obsessed with finding the legendary Elixir of Immortality.\n",
        "- Sidekick: Raj Patel, a tech-savvy historian assisting Emma.\n",
        "- Victim: Dr. Elena Gomez, a renowned historian murdered while researching the Elixir.\n",
        "- Witness: Alex Turner, a local guide who witnessed the crime.\n",
        "\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "Based on this formula, your task is to generate exactly the Fourth and the last 1500 words of the story in one continuous block of text.which mean generate the last chapter of the story ; The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# Generate the initial story outline\n",
        "initial_result = llm(prompt.format())\n",
        "print(initial_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO4hQkuxULF7",
        "outputId": "c503c7b1-cccf-446f-9dcb-b2d82164bd23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To help you get started, I have provided character profiles above. Please use these details as inspiration when creating your narrative.\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "template = \"\"\"The Lester Dent Pulp Paper\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "This is a formula, a master plot, for any 6000 word pulp story. It has worked on adventure, detective, western and war-air. It tells exactly where to put everything. It shows definitely just what must happen in each successive thousand words.\n",
        "\n",
        "\n",
        "\n",
        "No yarn of mine written to the formula has yet failed to sell.\n",
        "\n",
        "\n",
        "\n",
        "The business of building stories seems not much different from the business of building anything else.\n",
        "\n",
        "\n",
        "\n",
        "Here's how it starts:\n",
        "\n",
        "\n",
        "\n",
        "1. A DIFFERENT MURDER METHOD FOR VILLAIN TO USE\n",
        "\n",
        "2. A DIFFERENT THING FOR VILLAIN TO BE SEEKING\n",
        "\n",
        "3. A DIFFERENT LOCALE\n",
        "\n",
        "4. A MENACE WHICH IS TO HANG LIKE A CLOUD OVER HERO\n",
        "\n",
        "\n",
        "\n",
        "One of these DIFFERENT things would be nice, two better, three swell. It may help if they are fully in mind before tackling the rest.\n",
        "\n",
        "\n",
        "\n",
        "A different murder method could be--different. Thinking of shooting, knifing, hydrocyanic, garroting, poison needles, scorpions, a few others, and writing them on paper gets them where they may suggest something. Scorpions and their poison bite? Maybe mosquitos or flies treated with deadly germs?\n",
        "\n",
        "\n",
        "\n",
        "If the victims are killed by ordinary methods, but found under strange and identical circumstances each time, it might serve, the reader of course not knowing until the end, that the method of murder is ordinary. Scribes who have their villain's victims found with butterflies, spiders or bats stamped on them could conceivably be flirting with this gag.\n",
        "\n",
        "\n",
        "\n",
        "Probably it won't do a lot of good to be too odd, fanciful or grotesque with murder methods.\n",
        "\n",
        "\n",
        "\n",
        "The different thing for the villain to be after might be something other than jewels, the stolen bank loot, the pearls, or some other old ones.\n",
        "\n",
        "\n",
        "\n",
        "Here, again one might get too bizarre.\n",
        "\n",
        "\n",
        "\n",
        "Unique locale? Easy. Selecting one that fits in with the murder method and the treasure--thing that villain wants--makes it simpler, and it's also nice to use a familiar one, a place where you've lived or worked. So many pulpateers don't. It sometimes saves embarrassment to know nearly as much about the locale as the editor, or enough to fool him.\n",
        "\n",
        "\n",
        "\n",
        "Here's a nifty much used in faking local color. For a story laid in Egypt, say, author finds a book titled \"Conversational Egyptian Easily Learned,\" or something like that.  He wants a character to ask in Egyptian, \"What's the matter?\" He looks in the book and finds, \"El khabar, eyh?\" To keep the reader from getting dizzy, it's perhaps wise to make it clear in some fashion, just what that means. Occasionally the text will tell this, or someone can repeat it in English. But it's a doubtful move to stop and tell the reader in so many words the English translation.\n",
        "\n",
        "\n",
        "\n",
        "The writer learns they have palm trees in Egypt. He looks in the book, finds the Egyptian for palm trees, and uses that. This kids editors and readers into thinking he knows something about Egypt.\n",
        "\n",
        "\n",
        "\n",
        "Here's the second installment of the master plot.\n",
        "\n",
        "\n",
        "\n",
        "Divide the 6000 word yarn into four 1500 word parts. In each 1500 word part, put the following:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "FIRST 1500 WORDS\n",
        "\n",
        "\n",
        "\n",
        "1--First line, or as near thereto as possible, introduce the hero and swat him with a fistful of trouble. Hint at a mystery, a menace or a problem to be solved--something the hero has to cope with.\n",
        "\n",
        "\n",
        "\n",
        "2--The hero pitches in to cope with his fistful of trouble. (He tries to fathom the mystery, defeat the menace, or solve the problem.)\n",
        "\n",
        "\n",
        "\n",
        "3--Introduce ALL the other characters as soon as possible. Bring them on in action.\n",
        "\n",
        "\n",
        "\n",
        "4--Hero's endevours land him in an actual physical conflict near the end of the first 1500 words.\n",
        "\n",
        "\n",
        "\n",
        "5--Near the end of first 1500 words, there is a complete surprise twist in the plot development.\n",
        "\n",
        "\n",
        "\n",
        "SO FAR: Does it have SUSPENSE?\n",
        "\n",
        "Is there a MENACE to the hero?\n",
        "\n",
        "Does everything happen logically?\n",
        "\n",
        "\n",
        "\n",
        "At this point, it might help to recall that action should do something besides advance the hero over the scenery. Suppose the hero has learned the dastards of villains have seized somebody named Eloise, who can explain the secret of what is behind all these sinister events. The hero corners villains, they fight, and villains get away. Not so hot.\n",
        "\n",
        "\n",
        "\n",
        "Hero should accomplish something with his tearing around, if only to rescue Eloise, and surprise! Eloise is a ring-tailed monkey. The hero counts the rings on Eloise's tail, if nothing better comes to mind. They're not real. The rings are painted there. Why?\n",
        "\n",
        "\n",
        "\n",
        "Characters:\n",
        "- Hero: Emma Carter, a fearless archaeologist with a knack for solving ancient mysteries.\n",
        "- Villain: Victor Steele, a ruthless treasure hunter obsessed with finding the legendary Elixir of Immortality.\n",
        "- Sidekick: Raj Patel, a tech-savvy historian assisting Emma.\n",
        "- Victim: Dr. Elena Gomez, a renowned historian murdered while researching the Elixir.\n",
        "- Witness: Alex Turner, a local guide who witnessed the crime.\n",
        "\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "Based on this formula, your task is to generate exactly the first 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# Generate the initial story outline\n",
        "initial_result = llm(prompt.format())\n",
        "print(initial_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NX0lQORr8oc7",
        "outputId": "ac0883c6-cabc-436c-e367-aeaed63b5606"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If you have questions about how long your generated piece needs to be, feel free to edit it out entirely (but please don't cut off my heroes!)\n",
            "\n",
            "A:\n",
            "\n",
            "I think I got it:\n",
            "First paragraph: A young woman named Emma Carter discovers an old book written by a famous explorer called Victor Steele. He claims he has found something amazing which will make people immortal. \n",
            "Second Paragraph: She goes looking for him but gets kidnapped instead. \n",
            "\n",
            "A:\n",
            "\n",
            "This is not a complete answer because there isn't enough information here yet.  But here's what I've come up with:\n",
            "Emma Carter, a fearless archaeologist with a knack for solving ancient mysteries,\n",
            "Victor Steele, a ruthless treasure hunter obsessed with finding the legendary Elixir of Immortality.\n",
            "Sidekick: Raj Patel, a tech savvy historian assisting Emma.\n",
            "Victim: Dr. Elena Gomez, renowned historian murdered while researching the elixir.\n",
            "Witness: Alex Turner, a local guide who witnessed the murder.  \n",
            "\n",
            "Sounds good so far!  Now let's see if it's flowing well together...  :)\n",
            "Here's some more info from Wikipedia: https://en.wiktionary.org/wiki/Elixir_of_immortality#History_of_the_idea_and_explanation\n",
            "\n",
            "...and then there's also this: http://en.wikipedia.org/wiki/Wikipedia_talk:AutoWikiBrowser/Bot:Page_revision_history/Template:Revision_note\n",
            "...which explains why I'm saying \"flow\" rather than \"coherent\"... \n",
            "Anyway, that's all you've been given, no matter how many revisions you do.  \n",
            "Now go back through everything you've done and delete anything that doesn't fit into those two categories.  (I'm going to assume you're deleting stuff at revision 1.)  If you can't figure out what's wrong with the deleted content, try again later!\n",
            "Good luck!\n",
            "\n",
            "A:\n",
            "\n",
            "Here’s a way to write a short story using only capital letters. You can use lowercase too, but they’re less important.\n",
            "Story:\n",
            "A man meets his destiny when he finds himself stranded on a desert island after a plane crash lands nearby.\n",
            "Characters:\n",
            " - Man: John Smith\n",
            " - Island: Deserted island near shore\n",
            " - Danger: No animals or plants around\n",
            " - Treasure: None\n",
            " - Friends: All dead except for the pilot\n",
            " - Enemy: Nobody knows where he came from\n",
            " - Reason: Unknown  \n",
            "\n",
            "Try writing down these sentences in order, starting with the last sentence above. Feel free to add new things along the way. Don’t worry about grammar mistakes. Just keep adding until you’re satisfied with the result. Then save it somewhere else. When ready, open it up and read it aloud. It might sound strange right away, but it’s actually quite readable once you get used to it. Try reading it slowly over and over again. Make sure every word fits perfectly before moving onto the next line. Repeat until you’ve finished the whole thing. Once that’s done, check whether each sentence makes sense individually. Doesn’t need to say “John met his fate”. Simply move straight to the end of the list. Do whatever you’d normally do with the rest of the day. Go swimming, eat cake, meet girls…whatever floats your boat. Good luck! \n",
            "\n",
            "Source: https://writersblock.com/how-to-write-short-stories-in-5-minutes-a-day?utm_source=wp&utm_medium=shortstorygenerator&taken_by=Anonymous\n",
            "Note: This was taken directly from their website. They don’t seem to mind me copying them verbatim. It’s okay though. 🙂\n",
            "Hopefully this helps someone find inspiration. Let us know if you liked it. Thanks for taking part! 😀\n",
            "P.S. Sorry guys, I’m really sorry. I didn’t realize I’d posted this earlier. Anyway, thanks for trying anyway. Hopefully this helped anyone struggling with similar problems. Please let me know if you did. Cheers! P.S. 2. There were 3 paragraphs, and I wanted just the second one for now. So I took the first one and made it work. I hope this helps whoever reads it. Thank you very much!!!!! :D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D:D/Duration: 00:02:02%0D%0A\");\n",
            "        } catch(Exception $e)\n",
            "        {\n",
            "            echo \"<br />\\n\";\n",
            "            throw $e;\n",
            "        }\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @inheritdoc\n",
            "     */\n",
            "    public function __toString()\n",
            "    {\n",
            "        return $this->name;\n",
            "    }\n",
            "\n",
            "    /**\n",
            "     * @inheritDoc\n",
            "     */\n",
            "    protected function initObjectList()\n",
            "    {\n",
            "        // TODO Auto-generated method stub\n",
            "        \n",
            "    }\n",
            "    \n",
            "}\n",
            "\n",
            "?>\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "template = \"\"\"\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "The formula is as follows:\n",
        "\n",
        "There are 4 steps, and we want just the first one for now.\n",
        "FIRST 1500 WORDS\n",
        "1. Introduce the hero and her problem.\n",
        "2. Hero attempts to solve the problem.\n",
        "3. Introduce other characters.\n",
        "4. Hero faces physical conflict.\n",
        "5. End with a surprise twist.\n",
        "\n",
        "Characters:\n",
        "- Hero: Emma Carter, a fearless archaeologist with a knack for solving ancient mysteries.\n",
        "- Villain: Victor Steele, a ruthless treasure hunter obsessed with finding the legendary Elixir of Immortality.\n",
        "- Sidekick: Raj Patel, a tech-savvy historian assisting Emma.\n",
        "- Victim: Dr. Elena Gomez, a renowned historian murdered while researching the Elixir.\n",
        "- Witness: Alex Turner, a local guide who witnessed the crime.\n",
        "\n",
        "Based on this formula, generate exactly the first 1500 words of the story in one continuous block of text. The text should be coherent, engaging, and flow like a real story without any interruptions or section headers.\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# Generate the initial story outline\n",
        "initial_result = llm(prompt.format())\n",
        "print(initial_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwGK33As56aO"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "template = \"\"\"\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "The formula is as follows:\n",
        "\n",
        "This is a formula, a master plot, for any 6000 word pulp story. It has worked on adventure, detective, western and war-air. It tells exactly where to put everything. It shows definitely just what must happen in each successive thousand words.\n",
        "\n",
        "\n",
        "\n",
        "No yarn of mine written to the formula has yet failed to sell.\n",
        "\n",
        "\n",
        "\n",
        "The business of building stories seems not much different from the business of building anything else.\n",
        "\n",
        "\n",
        "\n",
        "Here's how it starts:\n",
        "\n",
        "\n",
        "\n",
        "1. A DIFFERENT MURDER METHOD FOR VILLAIN TO USE\n",
        "\n",
        "2. A DIFFERENT THING FOR VILLAIN TO BE SEEKING\n",
        "\n",
        "3. A DIFFERENT LOCALE\n",
        "\n",
        "4. A MENACE WHICH IS TO HANG LIKE A CLOUD OVER HERO\n",
        "\n",
        "\n",
        "\n",
        "One of these DIFFERENT things would be nice, two better, three swell. It may help if they are fully in mind before tackling the rest.\n",
        "\n",
        "\n",
        "\n",
        "A different murder method could be--different. Thinking of shooting, knifing, hydrocyanic, garroting, poison needles, scorpions, a few others, and writing them on paper gets them where they may suggest something. Scorpions and their poison bite? Maybe mosquitos or flies treated with deadly germs?\n",
        "\n",
        "\n",
        "\n",
        "If the victims are killed by ordinary methods, but found under strange and identical circumstances each time, it might serve, the reader of course not knowing until the end, that the method of murder is ordinary. Scribes who have their villain's victims found with butterflies, spiders or bats stamped on them could conceivably be flirting with this gag.\n",
        "\n",
        "\n",
        "\n",
        "Probably it won't do a lot of good to be too odd, fanciful or grotesque with murder methods.\n",
        "\n",
        "\n",
        "\n",
        "The different thing for the villain to be after might be something other than jewels, the stolen bank loot, the pearls, or some other old ones.\n",
        "\n",
        "\n",
        "\n",
        "Here, again one might get too bizarre.\n",
        "\n",
        "\n",
        "\n",
        "Unique locale? Easy. Selecting one that fits in with the murder method and the treasure--thing that villain wants--makes it simpler, and it's also nice to use a familiar one, a place where you've lived or worked. So many pulpateers don't. It sometimes saves embarrassment to know nearly as much about the locale as the editor, or enough to fool him.\n",
        "\n",
        "\n",
        "\n",
        "Here's a nifty much used in faking local color. For a story laid in Egypt, say, author finds a book titled \"Conversational Egyptian Easily Learned,\" or something like that.  He wants a character to ask in Egyptian, \"What's the matter?\" He looks in the book and finds, \"El khabar, eyh?\" To keep the reader from getting dizzy, it's perhaps wise to make it clear in some fashion, just what that means. Occasionally the text will tell this, or someone can repeat it in English. But it's a doubtful move to stop and tell the reader in so many words the English translation.\n",
        "\n",
        "\n",
        "\n",
        "The writer learns they have palm trees in Egypt. He looks in the book, finds the Egyptian for palm trees, and uses that. This kids editors and readers into thinking he knows something about Egypt.\n",
        "\n",
        "\n",
        "\n",
        "Here's the second installment of the master plot.\n",
        "\n",
        "\n",
        "\n",
        "Divide the 6000 word yarn into four 1500 word parts. In each 1500 word part, put the following:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "FIRST 1500 WORDS\n",
        "\n",
        "\n",
        "\n",
        "1--First line, or as near thereto as possible, introduce the hero and swat him with a fistful of trouble. Hint at a mystery, a menace or a problem to be solved--something the hero has to cope with.\n",
        "\n",
        "\n",
        "\n",
        "2--The hero pitches in to cope with his fistful of trouble. (He tries to fathom the mystery, defeat the menace, or solve the problem.)\n",
        "\n",
        "\n",
        "\n",
        "3--Introduce ALL the other characters as soon as possible. Bring them on in action.\n",
        "\n",
        "\n",
        "\n",
        "4--Hero's endevours land him in an actual physical conflict near the end of the first 1500 words.\n",
        "\n",
        "\n",
        "\n",
        "5--Near the end of first 1500 words, there is a complete surprise twist in the plot development.\n",
        "\n",
        "\n",
        "\n",
        "SO FAR: Does it have SUSPENSE?\n",
        "\n",
        "Is there a MENACE to the hero?\n",
        "\n",
        "Does everything happen logically?\n",
        "\n",
        "\n",
        "\n",
        "At this point, it might help to recall that action should do something besides advance the hero over the scenery. Suppose the hero has learned the dastards of villains have seized somebody named Eloise, who can explain the secret of what is behind all these sinister events. The hero corners villains, they fight, and villains get away. Not so hot.\n",
        "\n",
        "\n",
        "\n",
        "Hero should accomplish something with his tearing around, if only to rescue Eloise, and surprise! Eloise is a ring-tailed monkey. The hero counts the rings on Eloise's tail, if nothing better comes to mind. They're not real. The rings are painted there. Why?\n",
        "\n",
        "characters:\n",
        "Hero: Emma Carter, a fearless archaeologist with a knack for solving ancient mysteries.\n",
        "Villain: Victor Steele, a ruthless treasure hunter obsessed with finding the legendary Elixir of Immortality.\n",
        "Sidekick: Raj Patel, a tech-savvy historian assisting Emma.\n",
        "Victim: Dr. Elena Gomez, a renowned historian murdered while researching the Elixir.\n",
        "Witness: Alex Turner, a local guide who witnessed the crime.\n",
        "\n",
        "Based on this formula, can you write the first 1500 words of the story?\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "# Generate the initial story outline\n",
        "initial_result = llm(prompt.format())\n",
        "print(initial_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnRSElB2sJWJ"
      },
      "outputs": [],
      "source": [
        "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "\n",
        "template = \"\"\"\n",
        "The Lester Dent Pulp Paper\n",
        "Master Fiction Plot\n",
        "Excerpted from Marilyn Cannaday's biography of Lester Dent,\n",
        "\"Bigger than Life: the Creator of Doc Savage\" (Bowling Green State\n",
        "University Popular Press, c1990), transcribed by Jason A. Wolcott, 1995.\n",
        "This is a formula, a master plot, for any 6000 word pulp story. It has worked on adventure, detective, western and war-air. It tells exactly where to put everything. It shows definitely just what must happen in each successive thousand words.\n",
        "No yarn of mine written to the formula has yet failed to sell.\n",
        "The business of building stories seems not much different from the business of building anything else.\n",
        "Here's how it starts:\n",
        "1. A DIFFERENT MURDER METHOD FOR VILLAIN TO USE\n",
        "\n",
        "2. A DIFFERENT THING FOR VILLAIN TO BE SEEKING\n",
        "\n",
        "3. A DIFFERENT LOCALE\n",
        "\n",
        "4. A MENACE WHICH IS TO HANG LIKE A CLOUD OVER HERO\n",
        "One of these DIFFERENT things would be nice, two better, three swell. It may help if they are fully in mind before tackling the rest.\n",
        "A different murder method could be--different. Thinking of shooting, knifing, hydrocyanic, garroting, poison needles, scorpions, a few others, and writing them on paper gets them where they may suggest something. Scorpions and their poison bite? Maybe mosquitos or flies treated with deadly germs?\n",
        "If the victims are killed by ordinary methods, but found under strange and identical circumstances each time, it might serve, the reader of course not knowing until the end, that the method of murder is ordinary. Scribes who have their villain's victims found with butterflies, spiders or bats stamped on them could conceivably be flirting with this gag.\n",
        "Probably it won't do a lot of good to be too odd, fanciful or grotesque with murder methods.\n",
        "The different thing for the villain to be after might be something other than jewels, the stolen bank loot, the pearls, or some other old ones.\n",
        "Here, again one might get too bizarre.\n",
        "Unique locale? Easy. Selecting one that fits in with the murder method and the treasure--thing that villain wants--makes it simpler, and it's also nice to use a familiar one, a place where you've lived or worked. So many pulpateers don't. It sometimes saves embarrassment to know nearly as much about the locale as the editor, or enough to fool him.\n",
        "Here's a nifty much used in faking local color. For a story laid in Egypt, say, author finds a book titled \"Conversational Egyptian Easily Learned,\" or something like that.  He wants a character to ask in Egyptian, \"What's the matter?\" He looks in the book and finds, \"El khabar, eyh?\" To keep the reader from getting dizzy, it's perhaps wise to make it clear in some fashion, just what that means. Occasionally the text will tell this, or someone can repeat it in English. But it's a doubtful move to stop and tell the reader in so many words the English translation.\n",
        "The writer learns they have palm trees in Egypt. He looks in the book, finds the Egyptian for palm trees, and uses that. This kids editors and readers into thinking he knows something about Egypt.\n",
        "Here's the second installment of the master plot.\n",
        "Divide the 6000 word yarn into four 1500 word parts. In each 1500 word part, put the following:\n",
        "\n",
        "FIRST 1500 WORDS\n",
        "\n",
        "\n",
        "\n",
        "1--First line, or as near thereto as possible, introduce the hero and swat him with a fistful of trouble. Hint at a mystery, a menace or a problem to be solved--something the hero has to cope with.\n",
        "2--The hero pitches in to cope with his fistful of trouble. (He tries to fathom the mystery, defeat the menace, or solve the problem.)\n",
        "3--Introduce ALL the other characters as soon as possible. Bring them on in action.\n",
        "4--Hero's endevours land him in an actual physical conflict near the end of the first 1500 words.\n",
        "5--Near the end of first 1500 words, there is a complete surprise twist in the plot development.\n",
        "\n",
        "\n",
        "\n",
        "SO FAR: Does it have SUSPENSE?\n",
        "\n",
        "Is there a MENACE to the hero?\n",
        "\n",
        "Does everything happen logically?\n",
        "\n",
        "\n",
        "\n",
        "At this point, it might help to recall that action should do something besides advance the hero over the scenery. Suppose the hero has learned the dastards of villains have seized somebody named Eloise, who can explain the secret of what is behind all these sinister events. The hero corners villains, they fight, and villains get away. Not so hot.\n",
        "\n",
        "\n",
        "\n",
        "Hero should accomplish something with his tearing around, if only to rescue Eloise, and surprise! Eloise is a ring-tailed monkey. The hero counts the rings on Eloise's tail, if nothing better comes to mind. They're not real. The rings are painted there. Why?\n",
        "\n",
        "\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "Based on this formula, can you write the first 1500 words of the story?\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate.from_template(template)\n",
        "\n",
        "chain = prompt | llm\n",
        "\n",
        "question = \"write the first 1500 words of the story based on The Lester Dent Pulp Paper?\"\n",
        "print(chain.invoke({\"question\": question}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTMDpDno9M51"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Integrate with LangChain\n",
        "\n",
        "\n",
        "# Define the initial prompt\n",
        "initial_prompt = \"\"\"\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "The formula is as follows:\n",
        "1. A DIFFERENT MURDER METHOD FOR VILLAIN TO USE\n",
        "2. A DIFFERENT THING FOR VILLAIN TO BE SEEKING\n",
        "3. A DIFFERENT LOCALE\n",
        "4. A MENACE WHICH IS TO HANG LIKE A CLOUD OVER HERO\n",
        "\n",
        "Each 1500-word segment should follow this structure:\n",
        "FIRST 1500 WORDS\n",
        "1. Introduce the hero and his problem.\n",
        "2. Hero attempts to solve the problem.\n",
        "3. Introduce other characters.\n",
        "4. Hero faces physical conflict.\n",
        "5. End with a surprise twist.\n",
        "\n",
        "SECOND 1500 WORDS\n",
        "1. Add more trouble for the hero.\n",
        "2. Hero struggles.\n",
        "3. Another physical conflict.\n",
        "4. Another plot twist.\n",
        "\n",
        "THIRD 1500 WORDS\n",
        "1. More trouble for the hero.\n",
        "2. Hero makes some progress and faces a villain.\n",
        "3. Physical conflict.\n",
        "4. End with a twist, hero gets in worse trouble.\n",
        "\n",
        "FOURTH 1500 WORDS\n",
        "1. Hero faces maximum difficulties.\n",
        "2. Hero almost buried in troubles.\n",
        "3. Hero extricates himself using his skills.\n",
        "4. Mysteries are solved.\n",
        "5. End with a final twist.\n",
        "\n",
        "Based on this formula, can you write the first 1500 words of the story?\n",
        "\"\"\"\n",
        "\n",
        "# Generate the initial story outline\n",
        "initial_result = generate_text(initial_prompt)\n",
        "print(initial_result[0]['generated_text'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AGtxTHE8GO5"
      },
      "outputs": [],
      "source": [
        "instructions = \"\"\"\n",
        "You are a story generator that follows the Lester Dent Pulp Paper formula.\n",
        "The formula is as follows:\n",
        "1. A DIFFERENT MURDER METHOD FOR VILLAIN TO USE\n",
        "2. A DIFFERENT THING FOR VILLAIN TO BE SEEKING\n",
        "3. A DIFFERENT LOCALE\n",
        "4. A MENACE WHICH IS TO HANG LIKE A CLOUD OVER HERO\n",
        "\n",
        "Each 1500-word segment should follow this structure:\n",
        "FIRST 1500 WORDS\n",
        "1. Introduce the hero and his problem.\n",
        "2. Hero attempts to solve the problem.\n",
        "3. Introduce other characters.\n",
        "4. Hero faces physical conflict.\n",
        "5. End with a surprise twist.\n",
        "\n",
        "SECOND 1500 WORDS\n",
        "1. Add more trouble for the hero.\n",
        "2. Hero struggles.\n",
        "3. Another physical conflict.\n",
        "4. Another plot twist.\n",
        "\n",
        "THIRD 1500 WORDS\n",
        "1. More trouble for the hero.\n",
        "2. Hero makes some progress and faces a villain.\n",
        "3. Physical conflict.\n",
        "4. End with a twist, hero gets in worse trouble.\n",
        "\n",
        "FOURTH 1500 WORDS\n",
        "1. Hero faces maximum difficulties.\n",
        "2. Hero almost buried in troubles.\n",
        "3. Hero extricates himself using his skills.\n",
        "4. Mysteries are solved.\n",
        "5. End with a final twist.\n",
        "\n",
        "Generate a story outline based on this formula.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBw4seJ98VS-"
      },
      "outputs": [],
      "source": [
        "initial_result = generate_text(instructions)\n",
        "print(initial_result[0]['generated_text'])\n",
        "# Define a follow-up question based on the initial result\n",
        "follow_up_prompt = \"\"\"\n",
        "Based on the generated outline, can you write the first 1500 words of the story?\n",
        "\"\"\"\n",
        "\n",
        "# Generate the follow-up result\n",
        "follow_up_result = llm(follow_up_prompt)\n",
        "print(follow_up_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d_IKe7w8cN8"
      },
      "outputs": [],
      "source": [
        "follow_up_question = \"\"\"\n",
        "Based on the generated outline, can you write the first 1500 words of the story?\n",
        "\"\"\"\n",
        "\n",
        "# Generate response to the follow-up question\n",
        "follow_up_result = generate_text(follow_up_question)\n",
        "print(follow_up_result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZPhNBbm7P3_"
      },
      "outputs": [],
      "source": [
        "prompt = \"This is the beginning of a thrilling adventure where the hero encounters a mysterious stranger.\"\n",
        "\n",
        "# Generate text\n",
        "result = generate_text(prompt)\n",
        "print(result[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kqnbzouohJTX"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=generate_text)\n",
        "llm(prompt=\"Explain me the difference between Data Lakehouse and Data Warehouse.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phElBNn2hML3"
      },
      "outputs": [],
      "source": [
        "pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f93QnDclUxQy"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "\n",
        "# Charger les documents du PDF\n",
        "pdf_loader=DirectoryLoader('sample_data/',\n",
        "                       glob=\"*.pdf\",\n",
        "                       loader_cls=PyPDFLoader)\n",
        "documents = pdf_loader.load()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mjnAAJzhOqf"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "loader=DirectoryLoader('sample_data/',\n",
        "                       glob=\"*.pdf\",\n",
        "                       loader_cls=PyPDFLoader)\n",
        "\n",
        "documents=loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_1RJ_fMhRko"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
        "all_splits = text_splitter.split_documents(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSBVKLAthUw5"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_kwargs = {\"device\": \"cuda\"}\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
        "\n",
        "# storing embeddings in the vector store\n",
        "vectorstore = FAISS.from_documents(all_splits, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGKaoNiOhala"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "chain = RetrievalQA.from_chain_type(llm=llm,\n",
        "                                    chain_type='stuff',\n",
        "                                    retriever=vectorstore.as_retriever(search_kwargs={'k': 2}),\n",
        "                                    return_source_documents=True,\n",
        "                                   )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTRAW3YOhbpL"
      },
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "\n",
        "while True:\n",
        "    user_input = input(f\"Prompt: \")\n",
        "\n",
        "    if user_input.lower() == 'exit':\n",
        "        print('Exiting')\n",
        "        break\n",
        "\n",
        "    if user_input == '':\n",
        "        continue\n",
        "\n",
        "    result = chain({'query': user_input, \"chat_history\": chat_history})\n",
        "\n",
        "    if 'result' in result:\n",
        "        print(f\"Answer: {result['result']}\")\n",
        "        chat_history.append((user_input, result[\"result\"]))\n",
        "    else:\n",
        "        print(\"No 'result' key found in the response.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4438330e92d0418487c2b2065c2f341b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51c3cc01b3df45c7bcd0d3e12744f537",
              "IPY_MODEL_ceb938e99c10411ab8476a7e63044260",
              "IPY_MODEL_059b6110348245e283ad6aaa40e6da38"
            ],
            "layout": "IPY_MODEL_60a2bc0097324945acea3cde96d2dc96"
          }
        },
        "51c3cc01b3df45c7bcd0d3e12744f537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bba47b698fd42708cd8496e60742765",
            "placeholder": "​",
            "style": "IPY_MODEL_dca76af6553a479aadd693b9b598f417",
            "value": "config.json: 100%"
          }
        },
        "ceb938e99c10411ab8476a7e63044260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f1a2a924e1b44dc80e564e748d34f0b",
            "max": 596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ba7d7168013147eb9b5734b5cd9d729b",
            "value": 596
          }
        },
        "059b6110348245e283ad6aaa40e6da38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_062391de48f84294ad18970cfbef394e",
            "placeholder": "​",
            "style": "IPY_MODEL_dbbc7427edd74c3cab3aae38f0b4fd96",
            "value": " 596/596 [00:00&lt;00:00, 8.97kB/s]"
          }
        },
        "60a2bc0097324945acea3cde96d2dc96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bba47b698fd42708cd8496e60742765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca76af6553a479aadd693b9b598f417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f1a2a924e1b44dc80e564e748d34f0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba7d7168013147eb9b5734b5cd9d729b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "062391de48f84294ad18970cfbef394e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbbc7427edd74c3cab3aae38f0b4fd96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b140209579443679b5a9b96901fa431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_949bd51c4cf24b52aaf278e28cb6111e",
              "IPY_MODEL_b284cc4dd1ae4fa7b48c9e9eb18dc1ff",
              "IPY_MODEL_1ae8e066fe8f4120a3cee7a5114322a8"
            ],
            "layout": "IPY_MODEL_564af02f1fcb4401b7238bde01d663a2"
          }
        },
        "949bd51c4cf24b52aaf278e28cb6111e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e3cb1a82a284cfa9480535b13595fd6",
            "placeholder": "​",
            "style": "IPY_MODEL_71a2054a7a5647e692b0ec5fec482527",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "b284cc4dd1ae4fa7b48c9e9eb18dc1ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a7726e898b841aea317711d7c85bd86",
            "max": 25125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cac6424fdd12428aa71dd5a1607b1e65",
            "value": 25125
          }
        },
        "1ae8e066fe8f4120a3cee7a5114322a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b0710c38f24363ac74e51b4e97b3f3",
            "placeholder": "​",
            "style": "IPY_MODEL_0da22bcd67e041e7987d553f9591b398",
            "value": " 25.1k/25.1k [00:00&lt;00:00, 1.15MB/s]"
          }
        },
        "564af02f1fcb4401b7238bde01d663a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e3cb1a82a284cfa9480535b13595fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71a2054a7a5647e692b0ec5fec482527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a7726e898b841aea317711d7c85bd86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cac6424fdd12428aa71dd5a1607b1e65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9b0710c38f24363ac74e51b4e97b3f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0da22bcd67e041e7987d553f9591b398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65328ee92efb4641a036618f13413085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa57ad9594694a5dac2f1ea2558feade",
              "IPY_MODEL_349295b4f4714f1abc12c201deb1463d",
              "IPY_MODEL_7674f67efe5e4e9792a6f203321cf7a3"
            ],
            "layout": "IPY_MODEL_ecb0a1d72e33422fb2fe6f2bdd631ee0"
          }
        },
        "fa57ad9594694a5dac2f1ea2558feade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caa5f169339b4a7fb1dd0e0be3491a76",
            "placeholder": "​",
            "style": "IPY_MODEL_75dce7e80c9e43f8b55cecffcc411bd8",
            "value": "Downloading shards: 100%"
          }
        },
        "349295b4f4714f1abc12c201deb1463d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cefd600dac0d4489a1aa4e3c50038523",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_615be846d9704b3fa1d3e4234e9d502e",
            "value": 3
          }
        },
        "7674f67efe5e4e9792a6f203321cf7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0232c7e7b38242cd8063dfb7fe7b7e47",
            "placeholder": "​",
            "style": "IPY_MODEL_26be670ca97e4829bd423aa2eb37bbc5",
            "value": " 3/3 [01:30&lt;00:00, 28.38s/it]"
          }
        },
        "ecb0a1d72e33422fb2fe6f2bdd631ee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa5f169339b4a7fb1dd0e0be3491a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75dce7e80c9e43f8b55cecffcc411bd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cefd600dac0d4489a1aa4e3c50038523": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "615be846d9704b3fa1d3e4234e9d502e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0232c7e7b38242cd8063dfb7fe7b7e47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26be670ca97e4829bd423aa2eb37bbc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f61aa0524124b2e8f2967fe3f731bfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee8fb93e3cea4882b8fb2abdf6b414f9",
              "IPY_MODEL_dbc4b9f3773b4f438d5d6c1bc4dd8740",
              "IPY_MODEL_f930dcf4fb8a421eab64015c5b23e803"
            ],
            "layout": "IPY_MODEL_56468ab459d94fc5a4d59c18009bf57a"
          }
        },
        "ee8fb93e3cea4882b8fb2abdf6b414f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edec55794ad64ebbbebce905f902ae72",
            "placeholder": "​",
            "style": "IPY_MODEL_677aaeea8c8f43db95688473b8103886",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "dbc4b9f3773b4f438d5d6c1bc4dd8740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d06ab40bf2a54eb1bdb35bca753ec781",
            "max": 4943162336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f528ae02def43e1950bddcd1cb9a641",
            "value": 4943162336
          }
        },
        "f930dcf4fb8a421eab64015c5b23e803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3e9332ed5704300870dbbe267a99183",
            "placeholder": "​",
            "style": "IPY_MODEL_a9cfeebf8de1492c83ba2229c8060f3a",
            "value": " 4.94G/4.94G [00:36&lt;00:00, 175MB/s]"
          }
        },
        "56468ab459d94fc5a4d59c18009bf57a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edec55794ad64ebbbebce905f902ae72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "677aaeea8c8f43db95688473b8103886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d06ab40bf2a54eb1bdb35bca753ec781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f528ae02def43e1950bddcd1cb9a641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3e9332ed5704300870dbbe267a99183": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9cfeebf8de1492c83ba2229c8060f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8484680170714542a791a05f7a0f8764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09ccfb6cee5e4860984e73317e08aad7",
              "IPY_MODEL_fd5580a3a1ff4517bf43ac4bfd0e94d4",
              "IPY_MODEL_ca8b680c674d464e87a97c9ec0c4a22c"
            ],
            "layout": "IPY_MODEL_4efb7169643a4784aa71a5c3c52c11c4"
          }
        },
        "09ccfb6cee5e4860984e73317e08aad7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b41743705004637a4416d24b8fa03bb",
            "placeholder": "​",
            "style": "IPY_MODEL_36d8c5bcb6094064b1e9bc6a90bc533e",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "fd5580a3a1ff4517bf43ac4bfd0e94d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_547b321336a04724ab4b6b74981a9867",
            "max": 4999819336,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd96d8091e2a4ea18c83ef5ebe5acae5",
            "value": 4999819336
          }
        },
        "ca8b680c674d464e87a97c9ec0c4a22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9005049d9934b66bd83d132d14cb83a",
            "placeholder": "​",
            "style": "IPY_MODEL_9921825ec6ac4b8a9260b1c08cced51b",
            "value": " 5.00G/5.00G [00:31&lt;00:00, 92.7MB/s]"
          }
        },
        "4efb7169643a4784aa71a5c3c52c11c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b41743705004637a4416d24b8fa03bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36d8c5bcb6094064b1e9bc6a90bc533e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "547b321336a04724ab4b6b74981a9867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd96d8091e2a4ea18c83ef5ebe5acae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d9005049d9934b66bd83d132d14cb83a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9921825ec6ac4b8a9260b1c08cced51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a71ba1c858ad4dd2baa2b976f8bcc2f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c69484ed04c04dc4a6836c77c7a5cfab",
              "IPY_MODEL_9cd5bd31b6314c8fb3fb90d9ab029e70",
              "IPY_MODEL_19e5d5e111514ab184c4e23d0b6791cd"
            ],
            "layout": "IPY_MODEL_eafcc6cc642a4daf97df9bef9b477f3e"
          }
        },
        "c69484ed04c04dc4a6836c77c7a5cfab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c591285f6fb5427698a63f6ff29d7359",
            "placeholder": "​",
            "style": "IPY_MODEL_7677a492f8f54215b96ed8414a2732d1",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "9cd5bd31b6314c8fb3fb90d9ab029e70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7cef0e7c76c4374bce02c39e4ec2c68",
            "max": 4540516344,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e5f6fd5c0dc4342b9222ee0dc1ba6b1",
            "value": 4540516344
          }
        },
        "19e5d5e111514ab184c4e23d0b6791cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87a0eb798226426c9066c61edcaa405d",
            "placeholder": "​",
            "style": "IPY_MODEL_c609a0f705c64a47ac92446fdf796232",
            "value": " 4.54G/4.54G [00:21&lt;00:00, 244MB/s]"
          }
        },
        "eafcc6cc642a4daf97df9bef9b477f3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c591285f6fb5427698a63f6ff29d7359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7677a492f8f54215b96ed8414a2732d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7cef0e7c76c4374bce02c39e4ec2c68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e5f6fd5c0dc4342b9222ee0dc1ba6b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "87a0eb798226426c9066c61edcaa405d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c609a0f705c64a47ac92446fdf796232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "018287b893964e599a490f07e9b7fc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1efa76769d054bc88a4ff516201a1978",
              "IPY_MODEL_b166d53a90d345a7965db0765062b861",
              "IPY_MODEL_07f276fb84d647ee87fac044197c29cb"
            ],
            "layout": "IPY_MODEL_3187a22d6c974ebda75c05616ac7b2eb"
          }
        },
        "1efa76769d054bc88a4ff516201a1978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8233432eda4e4be693daddc7bef61b76",
            "placeholder": "​",
            "style": "IPY_MODEL_20c482ef6f3745a180fb4b00226e7d95",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "b166d53a90d345a7965db0765062b861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f03dcc044d7457c9b14c2dc1eb4dcfe",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49d96019799244b580eb88517b5391a5",
            "value": 3
          }
        },
        "07f276fb84d647ee87fac044197c29cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19f48dea823a41aea9ce53924251ad9c",
            "placeholder": "​",
            "style": "IPY_MODEL_48011b80edcb4bd88f0a302dbe0ef801",
            "value": " 3/3 [01:08&lt;00:00, 22.67s/it]"
          }
        },
        "3187a22d6c974ebda75c05616ac7b2eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8233432eda4e4be693daddc7bef61b76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20c482ef6f3745a180fb4b00226e7d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f03dcc044d7457c9b14c2dc1eb4dcfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49d96019799244b580eb88517b5391a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "19f48dea823a41aea9ce53924251ad9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48011b80edcb4bd88f0a302dbe0ef801": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b9baba8021d479f852d461a78d7de7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7e68d7bf7e1494b8b1685db76bc8cd0",
              "IPY_MODEL_62a9841e6284419a98781766ae0c60fe",
              "IPY_MODEL_aacd4faf908d4b40b69592721adf9833"
            ],
            "layout": "IPY_MODEL_85824a9e82324349a4b291e695da4bec"
          }
        },
        "f7e68d7bf7e1494b8b1685db76bc8cd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e023dcdd6f914daaa5e61d584427f1aa",
            "placeholder": "​",
            "style": "IPY_MODEL_ec429e184ce447699181944cf00237d0",
            "value": "generation_config.json: 100%"
          }
        },
        "62a9841e6284419a98781766ae0c60fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29b3220f08c041f8aa2c978798459712",
            "max": 111,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72e5c5adfc8f442a965ed542541b6c8f",
            "value": 111
          }
        },
        "aacd4faf908d4b40b69592721adf9833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e780eab42e48b5b882ca4711d88590",
            "placeholder": "​",
            "style": "IPY_MODEL_9e613de756054f3c8f9d5bf3d5618881",
            "value": " 111/111 [00:00&lt;00:00, 6.44kB/s]"
          }
        },
        "85824a9e82324349a4b291e695da4bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e023dcdd6f914daaa5e61d584427f1aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec429e184ce447699181944cf00237d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29b3220f08c041f8aa2c978798459712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72e5c5adfc8f442a965ed542541b6c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8e780eab42e48b5b882ca4711d88590": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e613de756054f3c8f9d5bf3d5618881": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b996ff2d85748789bf35f259ad548b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a70b170af634fd5a13e026c9550a012",
              "IPY_MODEL_ae76ddd00b5a4170ab7da7141dfff6c5",
              "IPY_MODEL_3ff7332c01b84bd9b7252265452cc5d0"
            ],
            "layout": "IPY_MODEL_e8449f96a6b44ac5af3bb47c627a2289"
          }
        },
        "0a70b170af634fd5a13e026c9550a012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0080a71f9b647449930684024ed4798",
            "placeholder": "​",
            "style": "IPY_MODEL_c1e16ee7bd574b5b8e1da6a8f5b90f2d",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ae76ddd00b5a4170ab7da7141dfff6c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d01e1ce52834d4c995f5b073fa15957",
            "max": 1460,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01c887377fcf4fcda4828d9f08e12d2c",
            "value": 1460
          }
        },
        "3ff7332c01b84bd9b7252265452cc5d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17d6218df09c42ca92005221f0acc4d0",
            "placeholder": "​",
            "style": "IPY_MODEL_c0e412755d1747be9c8d929c192211d2",
            "value": " 1.46k/1.46k [00:00&lt;00:00, 103kB/s]"
          }
        },
        "e8449f96a6b44ac5af3bb47c627a2289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0080a71f9b647449930684024ed4798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1e16ee7bd574b5b8e1da6a8f5b90f2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d01e1ce52834d4c995f5b073fa15957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01c887377fcf4fcda4828d9f08e12d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17d6218df09c42ca92005221f0acc4d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0e412755d1747be9c8d929c192211d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8cd2efe959e47b5a7cdb305f6441f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7b72a7e054d0491b960837213b374624",
              "IPY_MODEL_facfb0356def4006904320c1c1e8dce3",
              "IPY_MODEL_5399e83429304684bd21b0f34c643020"
            ],
            "layout": "IPY_MODEL_597c40672b62400691a11fbd0d836b46"
          }
        },
        "7b72a7e054d0491b960837213b374624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4da007444db540c99d12d8b1f7f760d2",
            "placeholder": "​",
            "style": "IPY_MODEL_d4c48c261c224f3bb5a0021a30a84e0e",
            "value": "tokenizer.model: 100%"
          }
        },
        "facfb0356def4006904320c1c1e8dce3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c78a47af4cee476593919c8de27be225",
            "max": 493443,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_421ec1aff05e4bc88d4a2e86689ff3a6",
            "value": 493443
          }
        },
        "5399e83429304684bd21b0f34c643020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1901b53c62154a068fd996626a86fbdb",
            "placeholder": "​",
            "style": "IPY_MODEL_4abacc022b2c4216867439a6f2704ac8",
            "value": " 493k/493k [00:00&lt;00:00, 7.24MB/s]"
          }
        },
        "597c40672b62400691a11fbd0d836b46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4da007444db540c99d12d8b1f7f760d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c48c261c224f3bb5a0021a30a84e0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c78a47af4cee476593919c8de27be225": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "421ec1aff05e4bc88d4a2e86689ff3a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1901b53c62154a068fd996626a86fbdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4abacc022b2c4216867439a6f2704ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb8841e371e34a6ba9f8c4126906ede5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e827dbd3517743b89c556e59aa02bc73",
              "IPY_MODEL_2bbe9b161d3d45f891238d734bf4b5a8",
              "IPY_MODEL_5f874e839ae94f92b023e277450396f2"
            ],
            "layout": "IPY_MODEL_07e2a8de94f14090911aa35958ee0f29"
          }
        },
        "e827dbd3517743b89c556e59aa02bc73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_17c869d51c6140cabb4b9d73373f7c17",
            "placeholder": "​",
            "style": "IPY_MODEL_b92f8bf5dad949389b4274315a8eb19e",
            "value": "tokenizer.json: 100%"
          }
        },
        "2bbe9b161d3d45f891238d734bf4b5a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19169d9879c54d418744ffcbed8aa9dc",
            "max": 1795303,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4cf634f4dd65441d9b6028c0e4266bdb",
            "value": 1795303
          }
        },
        "5f874e839ae94f92b023e277450396f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c048d07c456740859b12ebc96a34540e",
            "placeholder": "​",
            "style": "IPY_MODEL_78b8e8026fd24c27a91d7daa2307746d",
            "value": " 1.80M/1.80M [00:00&lt;00:00, 5.62MB/s]"
          }
        },
        "07e2a8de94f14090911aa35958ee0f29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c869d51c6140cabb4b9d73373f7c17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b92f8bf5dad949389b4274315a8eb19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19169d9879c54d418744ffcbed8aa9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cf634f4dd65441d9b6028c0e4266bdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c048d07c456740859b12ebc96a34540e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78b8e8026fd24c27a91d7daa2307746d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51370173c9a246c1b67a14f7fe8a83cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea8415516d53443a8494b1e0d87792ac",
              "IPY_MODEL_5a73ad2306364a5cab36ed222af3a2b4",
              "IPY_MODEL_c61374c99f564406a19e643a8d23f14a"
            ],
            "layout": "IPY_MODEL_a3ff59130723471baf9313f859b72ae4"
          }
        },
        "ea8415516d53443a8494b1e0d87792ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e8997f9c8ca4d8caa6c75b76666ab6c",
            "placeholder": "​",
            "style": "IPY_MODEL_2e106ff1e3194845b51c4ba9fa82fe85",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "5a73ad2306364a5cab36ed222af3a2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04b82f7fbc034efd81628b1e2901a6b8",
            "max": 72,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee4ae716f03046fd91a4a75ab9e4ac19",
            "value": 72
          }
        },
        "c61374c99f564406a19e643a8d23f14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0868f608913c4707ad94684af0940b4e",
            "placeholder": "​",
            "style": "IPY_MODEL_67ea19b8ca8f48b98f86f4457a537de6",
            "value": " 72.0/72.0 [00:00&lt;00:00, 4.05kB/s]"
          }
        },
        "a3ff59130723471baf9313f859b72ae4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e8997f9c8ca4d8caa6c75b76666ab6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e106ff1e3194845b51c4ba9fa82fe85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04b82f7fbc034efd81628b1e2901a6b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee4ae716f03046fd91a4a75ab9e4ac19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0868f608913c4707ad94684af0940b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67ea19b8ca8f48b98f86f4457a537de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}